–û—Ç–ª–∏—á–Ω–æ! –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ ‚Äî —ç—Ç–æ —Ö–æ—Ä–æ—à–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏, –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞. –Ø –ø—Ä–æ–≤–µ–ª –ø–æ–ª–Ω—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞, —Å—Ç–∞—Ä–∞—è—Å—å —É–ª—É—á—à–∏—Ç—å –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é, —á–∏—Ç–∞–µ–º–æ—Å—Ç—å –∏ —Å–ª–µ–¥–æ–≤–∞—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º –ª—É—á—à–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª.

–û—Å–Ω–æ–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:

1.  **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ `MainWindow`:**
    *   –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (`__init__`) —Ä–∞–∑–¥–µ–ª–µ–Ω–∞ –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏: `_init_state`, `_load_config`, `_init_ui`, `_connect_signals`.
    *   –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤ –¥–ª—è –≤–∫–ª–∞–¥–æ–∫ –∏ –ø–∞–Ω–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã–Ω–µ—Å–µ–Ω–æ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã.
    *   –û–±—â–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã UI (–≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –ø–æ–ª–µ –¥–ª—è –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É) —Å–æ–∑–¥–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ (`_create_source_selector_row`, `_create_file_path_row`), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞.
2.  **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º:** –î–æ–±–∞–≤–ª–µ–Ω—ã —Ñ–ª–∞–≥–∏ (`_is_calibrating`, `_is_working`) –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ñ–ª–∞–≥–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ç–æ–∫–æ–≤ (`_calib_stop_flag`, `_working_stop_flag`).
3.  **–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:** –õ–æ–≥–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è `self.detection_params` –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º. –ü—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ —Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã—Ö –∫–ª—é—á–µ–π.
4.  **–†–∞–±–æ—Ç–∞ —Å –ø–æ—Ç–æ–∫–∞–º–∏:** –Ø–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è `threading.Thread`. –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ `is_alive()` –∏ –ø–æ–ø—ã—Ç–∫–∞ `join()` –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤ –≤ `closeEvent` –¥–ª—è –±–æ–ª–µ–µ —á–∏—Å—Ç–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (—Ö–æ—Ç—è `daemon=True` –æ–±—ã—á–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ).
5.  **–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ:** –§—É–Ω–∫—Ü–∏—è `frame_to_qpixmap` —Å–¥–µ–ª–∞–Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º –º–µ—Ç–æ–¥–æ–º `Utils.frame_to_qpixmap` –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –≤—ã–Ω–µ—Å–µ–Ω–∞ –≤–æ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å `Utils`.
6.  **–†–∞–±–æ—á–∞—è –æ–±–ª–∞—Å—Ç—å:** –õ–æ–≥–∏–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ (`_prepare_working_area`) –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ *–ø–µ—Ä–µ–¥* –∑–∞–ø—É—Å–∫–æ–º —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å GUI-–≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º –∏–∑ —Ñ–æ–Ω–æ–≤–æ–≥–æ –ø–æ—Ç–æ–∫–∞. –ú–µ—Ç–æ–¥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (`confirm_working_area`) –æ—Å—Ç–∞–≤–ª–µ–Ω –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —Ç–∞–∫ –∫–∞–∫ `QEventLoop` ‚Äî —Ä–∞–±–æ—á–∏–π —Å–ø–æ—Å–æ–± –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ *–æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞* –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
7.  **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å:** –î–æ–±–∞–≤–ª–µ–Ω—ã –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —É–ª—É—á—à–µ–Ω—ã –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –∫–æ–¥ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏. –ò–º–ø–æ—Ä—Ç—ã —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω—ã.
8.  **–ö–ª–∞—Å—Å `Utils`:** –î–æ–±–∞–≤–ª–µ–Ω –Ω–µ–±–æ–ª—å—à–æ–π –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—â–∏—Ö —É—Ç–∏–ª–∏—Ç (–ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ `frame_to_qpixmap` –∏ `toggle_layout_visibility`).
9.  **–ú–æ–¥—É–ª–∏ (`ultimate.py`, `calib.py`, `robot_comm.py`, `variables.py`):**
    *   –í `ultimate.py`: –ù–µ–±–æ–ª—å—à–∏–µ —É–ª—É—á—à–µ–Ω–∏—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏, –ø–µ—Ä–µ–¥–∞—á–∞ `detection_params` –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä `WorkingArea`.
    *   –í `calib.py`: –£–ª—É—á—à–µ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è `print`, –Ω–µ–±–æ–ª—å—à–∞—è —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è.
    *   –í `robot_comm.py`: –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö. –£–ª—É—á—à–µ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è.
    *   –í `variables.py`: –ö–æ–¥ –æ—Å—Ç–∞–≤–ª–µ–Ω –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–≤–æ—é —Ä–æ–ª—å —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∫–æ–Ω—Å—Ç–∞–Ω—Ç. –£–±—Ä–∞–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ `source_type`. –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ `APP_DIR`, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.

–í–æ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥:

**`main_refactored.py`**

```python
# main_refactored.py
import sys
import os
import numpy as np
import cv2
import socket
import threading
import time
import logging
import json
from functools import partial
from concurrent.futures import ThreadPoolExecutor

from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QTabWidget, QHBoxLayout,
    QVBoxLayout, QPushButton, QLabel, QLineEdit, QFormLayout,
    QComboBox, QFileDialog, QMessageBox, QSizePolicy, QCheckBox, QSlider
)
from PyQt5.QtCore import Qt, QEventLoop
from PyQt5.QtGui import QImage, QPixmap

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
import variables as var
from robot_comm import RobotComm
from calib import calibrate_camera_gui
from ultimate import WorkingArea, ObjectDetector, undistort_frame
from debug_window import DebugWindow  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ DebugWindow –≤—ã–Ω–µ—Å–µ–Ω –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
from utils import Utils  # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å

logging.basicConfig(filename=var.LOG_FILE,
                    level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

class MainWindow(QMainWindow):
    DEFAULT_DETECTION_PARAMS = {
        "SCALE": var.SCALE,
        "BLUR_KERNEL": var.BLUR_KERNEL,
        "CANNY_LOW": var.CANNY_LOW,
        "CANNY_HIGH": var.CANNY_HIGH,
        "MIN_AREA": var.MIN_AREA,
        "MAX_AREA": var.MAX_AREA,
        "CONVERSION_FACTOR": var.CONVERSION_FACTOR,
    }

    def __init__(self):
        super().__init__()
        self._init_state()
        self._load_config()
        self._init_ui()
        self._connect_signals()
        self.working_area_processor = WorkingArea(
            detection_params=self.detection_params,
            confirmation_callback=self.confirm_working_area,
            parent=self
        )

    def _init_state(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–∫–Ω–∞."""
        self.robot = None
        self.working_area_mask = None
        self.last_overlay_frame = None  # –î–ª—è –ø–æ–∫–∞–∑–∞ –∫–∞–¥—Ä–∞ —Å –æ–±–ª–∞—Å—Ç—å—é
        self._detector = None
        self._working_thread = None
        self._calib_thread = None
        self._working_stop_flag = False
        self._calib_stop_flag = False
        self._is_working = False
        self._is_calibrating = False
        self.param_widgets = {} # –°–ª–æ–≤–∞—Ä–∏–∫ –¥–ª—è –≤–∏–¥–∂–µ—Ç–æ–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

    def _load_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ü–∏–∏)."""
        self.detection_params = self.DEFAULT_DETECTION_PARAMS.copy()
        try:
            if os.path.exists(var.PARAMETERS_CONFIG):
                with open(var.PARAMETERS_CONFIG, "r") as f:
                    loaded_params = json.load(f)
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
                    for key in self.detection_params:
                        if key in loaded_params:
                            self.detection_params[key] = loaded_params[key]
                    print("[INFO] Detection parameters loaded from:", var.PARAMETERS_CONFIG)
            else:
                print("[INFO] No saved parameter config found. Using defaults.")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç
                self.save_detection_params()

        except Exception as e:
            print(f"[ERROR] Failed to load or process detection parameters: {e}")
            QMessageBox.warning(self, "Config Error",
                                f"Could not load detection parameters from {var.PARAMETERS_CONFIG}.\nUsing default values.\nError: {e}")
            # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —á—Ç–µ–Ω–∏—è
            self.detection_params = self.DEFAULT_DETECTION_PARAMS.copy()


    def _init_ui(self):
        """–°–æ–∑–¥–∞–µ—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å."""
        self.setWindowTitle("Pill Project Pilot GUI")
        self.resize(1000, 700) # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–º —Ä–∞–∑–º–µ—Ä

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # –í–µ—Ä—Ö–Ω–∏–π –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –º–∞–∫–µ—Ç –¥–ª—è –≤–∫–ª–∞–¥–æ–∫ –∏ –ø–∞–Ω–µ–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        top_layout = QHBoxLayout()

        # --- –í–∫–ª–∞–¥–∫–∏ ---
        self.tabs = QTabWidget()
        self.tabs.addTab(self._create_working_mode_tab(), "Working Mode")
        # –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –Ω–µ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–∫
        self.tabs.addTab(QLabel("Data Collection (Not Implemented)"), "Data Collection")
        self.tabs.addTab(QLabel("Data Analysis (Not Implemented)"), "Data Analysis")
        self.tabs.addTab(self._create_modbus_tab(), "Modbus TCP")
        self.tabs.addTab(self._create_calibration_tab(), "Calibration")
        top_layout.addWidget(self.tabs, 1) # –î–∞–µ–º –≤–∫–ª–∞–¥–∫–∞–º –±–æ–ª—å—à–µ –º–µ—Å—Ç–∞

        # --- –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ---
        param_control_widget = QWidget()
        param_control_widget.setLayout(self._create_param_controls())
        param_control_widget.setFixedWidth(200) # –§–∏–∫—Å–∏—Ä—É–µ–º —à–∏—Ä–∏–Ω—É –ø–∞–Ω–µ–ª–∏
        top_layout.addWidget(param_control_widget)

        main_layout.addLayout(top_layout)

        # –û–±–Ω–æ–≤–ª—è–µ–º UI –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞—á–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)
        self.update_calibration_source_ui()
        self.update_working_source_ui()

    def _connect_signals(self):
        """–ü–æ–¥–∫–ª—é—á–∞–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –≤–∏–¥–∂–µ—Ç–æ–≤ –∫ —Å–ª–æ—Ç–∞–º (–º–µ—Ç–æ–¥–∞–º)."""
        # –í–∫–ª–∞–¥–∫–∞ Modbus
        self.modbus_refresh_button.clicked.connect(self._scan_network_for_modbus)
        self.modbus_device_selector.currentTextChanged.connect(lambda ip: self.modbus_ip_input.setText(ip))
        self.modbus_connect_button.clicked.connect(self._connect_modbus)
        self.modbus_disconnect_button.clicked.connect(self._disconnect_modbus)

        # –í–∫–ª–∞–¥–∫–∞ –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
        self.calib_source_selector.currentIndexChanged.connect(self.update_calibration_source_ui)
        self.calib_video_browse_button.clicked.connect(self._browse_calibration_video)
        self.calib_video_path_input.mousePressEvent = lambda e: self._browse_calibration_video() # –ö–ª–∏–∫ –Ω–∞ –ø–æ–ª–µ
        self.calib_camera_index_input.editingFinished.connect(self._update_calibration_camera_index)
        self.calib_start_button.clicked.connect(self.start_calibration)
        self.calib_stop_button.clicked.connect(self.stop_calibration)

        # –í–∫–ª–∞–¥–∫–∞ –†–∞–±–æ—á–∏–π —Ä–µ–∂–∏–º
        self.working_source_selector.currentIndexChanged.connect(self.update_working_source_ui)
        self.working_video_browse_button.clicked.connect(self._browse_working_video)
        self.working_video_path_input.mousePressEvent = lambda e: self._browse_working_video() # –ö–ª–∏–∫ –Ω–∞ –ø–æ–ª–µ
        self.working_camera_index_input.editingFinished.connect(self._update_working_camera_index)
        self.working_start_button.clicked.connect(self.start_working_mode)
        self.working_stop_button.clicked.connect(self.stop_working_mode)

        # –ü–∞–Ω–µ–ª—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        self.debug_checkbox.stateChanged.connect(self._toggle_debug_window)


    # --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã —Å–æ–∑–¥–∞–Ω–∏—è UI ---

    def _create_source_selector_row(self, label_text, items, current_index=0):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É —Å Label –∏ ComboBox –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
        layout = QHBoxLayout()
        layout.addWidget(QLabel(label_text))
        combo_box = QComboBox()
        combo_box.addItems(items)
        combo_box.setCurrentIndex(current_index)
        layout.addWidget(combo_box)
        return layout, combo_box

    def _create_file_path_row(self, label_text, default_path):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—É—Ç–∏ –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É."""
        layout = QHBoxLayout()
        layout.addWidget(QLabel(label_text))
        line_edit = QLineEdit(default_path)
        line_edit.setReadOnly(True) # –î–µ–ª–∞–µ–º ReadOnly, –≤—ã–±–æ—Ä —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫—É/–∫–ª–∏–∫
        browse_button = QPushButton("...")
        browse_button.setFixedWidth(30)
        layout.addWidget(line_edit)
        layout.addWidget(browse_button)
        return layout, line_edit, browse_button

    def _create_index_input_row(self, label_text, default_index):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è –≤–≤–æ–¥–∞ –∏–Ω–¥–µ–∫—Å–∞ –∫–∞–º–µ—Ä—ã."""
        layout = QHBoxLayout()
        layout.addWidget(QLabel(label_text))
        line_edit = QLineEdit(str(default_index))
        layout.addWidget(line_edit)
        return layout, line_edit

    # --- –°–æ–∑–¥–∞–Ω–∏–µ –≤–∫–ª–∞–¥–æ–∫ ---

    def _create_modbus_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.setAlignment(Qt.AlignTop)

        # –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        scan_layout = QHBoxLayout()
        self.modbus_device_selector = QComboBox()
        self.modbus_refresh_button = QPushButton("Scan Network")
        scan_layout.addWidget(QLabel("Found Devices:"))
        scan_layout.addWidget(self.modbus_device_selector, 1)
        scan_layout.addWidget(self.modbus_refresh_button)
        layout.addLayout(scan_layout)

        # –í–≤–æ–¥ IP –∏ –ø–æ—Ä—Ç–∞
        form_layout = QFormLayout()
        self.modbus_ip_input = QLineEdit(var.MODBUS_TCP_HOST)
        self.modbus_port_input = QLineEdit(str(var.MODBUS_TCP_PORT))
        form_layout.addRow("IP Address:", self.modbus_ip_input)
        form_layout.addRow("Port:", self.modbus_port_input)
        layout.addLayout(form_layout)

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ —Å—Ç–∞—Ç—É—Å
        button_layout = QHBoxLayout()
        self.modbus_connect_button = QPushButton("Connect")
        self.modbus_disconnect_button = QPushButton("Disconnect")
        button_layout.addWidget(self.modbus_connect_button)
        button_layout.addWidget(self.modbus_disconnect_button)
        layout.addLayout(button_layout)

        self.modbus_status_label = QLabel("Status: Disconnected")
        layout.addWidget(self.modbus_status_label)

        # –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–Ω–æ–ø–æ–∫
        self.modbus_disconnect_button.setEnabled(False)

        return tab

    def _create_calibration_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.setAlignment(Qt.AlignTop)

        # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_layout, self.calib_source_selector = self._create_source_selector_row(
            "Calibration Source:", ["Calibration video", "Camera"]
        )
        layout.addLayout(source_layout)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–∏–¥–µ–æ
        self.calib_video_layout_container = QWidget() # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è/–ø–æ–∫–∞–∑–∞
        video_container_layout = QVBoxLayout(self.calib_video_layout_container)
        video_container_layout.setContentsMargins(0,0,0,0)
        video_row_layout, self.calib_video_path_input, self.calib_video_browse_button = self._create_file_path_row(
            "Video Path:", var.CALIBRATION_VIDEO_PATH
        )
        video_container_layout.addLayout(video_row_layout)
        layout.addWidget(self.calib_video_layout_container)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–º–µ—Ä—ã
        self.calib_camera_layout_container = QWidget() # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Å–∫—Ä—ã—Ç–∏—è/–ø–æ–∫–∞–∑–∞
        camera_container_layout = QVBoxLayout(self.calib_camera_layout_container)
        camera_container_layout.setContentsMargins(0,0,0,0)
        camera_row_layout, self.calib_camera_index_input = self._create_index_input_row(
             "Camera Index:", var.CAMERA_INDEX
        )
        camera_container_layout.addLayout(camera_row_layout)
        layout.addWidget(self.calib_camera_layout_container)

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π
        calib_button_row = QHBoxLayout()
        self.calib_start_button = QPushButton("Start Calibration")
        self.calib_stop_button = QPushButton("Stop Calibration")
        self.calib_stop_button.setEnabled(False) # –°—Ç–æ–ø –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ
        calib_button_row.addWidget(self.calib_start_button)
        calib_button_row.addWidget(self.calib_stop_button)
        layout.addLayout(calib_button_row)

        # –û–±–ª–∞—Å—Ç—å –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ
        self.calib_video_label = QLabel("Calibration preview will appear here")
        self.calib_video_label.setMinimumSize(320, 240)
        self.calib_video_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        self.calib_video_label.setAlignment(Qt.AlignCenter)
        self.calib_video_label.setStyleSheet("background-color: black; color: grey;")
        layout.addWidget(self.calib_video_label, 1) # –ó–∞–Ω–∏–º–∞–µ—Ç –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –º–µ—Å—Ç–æ

        return tab

    def _create_working_mode_tab(self):
        tab = QWidget()
        layout = QVBoxLayout(tab)
        layout.setAlignment(Qt.AlignTop)

        # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_layout, self.working_source_selector = self._create_source_selector_row(
            "Working Source:", ["Working video", "Camera"]
        )
        layout.addLayout(source_layout)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤–∏–¥–µ–æ
        self.working_video_layout_container = QWidget() # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä
        video_container_layout = QVBoxLayout(self.working_video_layout_container)
        video_container_layout.setContentsMargins(0,0,0,0)
        video_row, self.working_video_path_input, self.working_video_browse_button = self._create_file_path_row(
            "Video Path:", var.WORKING_VIDEO_PATH
        )
        video_container_layout.addLayout(video_row)
        layout.addWidget(self.working_video_layout_container)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–∞–º–µ—Ä—ã
        self.working_camera_layout_container = QWidget() # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä
        camera_container_layout = QVBoxLayout(self.working_camera_layout_container)
        camera_container_layout.setContentsMargins(0,0,0,0)
        camera_row, self.working_camera_index_input = self._create_index_input_row(
            "Camera Index:", var.CAMERA_INDEX
        )
        camera_container_layout.addLayout(camera_row)
        layout.addWidget(self.working_camera_layout_container)

        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏ –æ–ø—Ü–∏—è Modbus
        button_row = QHBoxLayout()
        self.working_start_button = QPushButton("Start Working Mode")
        self.working_stop_button = QPushButton("Stop Working Mode")
        self.modbus_checkbox = QCheckBox("Send data via Modbus")
        self.working_stop_button.setEnabled(False)
        button_row.addWidget(self.working_start_button)
        button_row.addWidget(self.working_stop_button)
        button_row.addWidget(self.modbus_checkbox)
        layout.addLayout(button_row)

        # –õ–µ–π–±–ª –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—á–µ–π –∑–æ–Ω—ã (–∏–∑–Ω–∞—á–∞–ª—å–Ω–æ —Å–∫—Ä—ã—Ç)
        self.working_area_confirm_label = QLabel("Is this the correct working area?")
        self.working_area_confirm_label.setAlignment(Qt.AlignCenter)
        self.working_area_confirm_label.setVisible(False)
        layout.addWidget(self.working_area_confirm_label)

        # –ö–Ω–æ–ø–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—á–µ–π –∑–æ–Ω—ã (–∏–∑–Ω–∞—á–∞–ª—å–Ω–æ —Å–∫—Ä—ã—Ç—ã)
        self.working_confirm_layout_widget = QWidget() # Widget to hold confirm buttons layout
        self.working_confirm_layout = QHBoxLayout(self.working_confirm_layout_widget)
        self.confirm_button_yes = QPushButton("Yes, Confirm Area")
        self.confirm_button_no = QPushButton("No, Try Again")
        self.working_confirm_layout.addWidget(self.confirm_button_yes)
        self.working_confirm_layout.addWidget(self.confirm_button_no)
        self.working_confirm_layout_widget.setVisible(False)
        layout.addWidget(self.working_confirm_layout_widget)


        # –û–±–ª–∞—Å—Ç—å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ
        self.working_video_label = QLabel("Working mode video will appear here")
        self.working_video_label.setMinimumSize(320, 240)
        self.working_video_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        self.working_video_label.setAlignment(Qt.AlignCenter)
        self.working_video_label.setStyleSheet("background-color: black; color: grey;")
        layout.addWidget(self.working_video_label, 1) # –ó–∞–Ω–∏–º–∞–µ—Ç –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –º–µ—Å—Ç–æ


        return tab

    def _create_param_controls(self):
        panel_layout = QVBoxLayout()
        panel_layout.setAlignment(Qt.AlignTop)
        panel_layout.setSpacing(10)

        title_label = QLabel("Detection Parameters")
        title_label.setAlignment(Qt.AlignCenter)
        panel_layout.addWidget(title_label)

        self.debug_checkbox = QCheckBox("Show Debug View")
        panel_layout.addWidget(self.debug_checkbox)
        panel_layout.addSpacing(10)

        param_specs = { # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: –∏–º—è -> (min, max, step, —Ç–∏–ø(int/float))
            "SCALE": (0.1, 1.5, 0.01, float),
            "BLUR_KERNEL": (1, 21, 2, int), # –®–∞–≥ 2 –¥–ª—è –Ω–µ—á–µ—Ç–Ω—ã—Ö
            "CANNY_LOW": (0, 255, 1, int),
            "CANNY_HIGH": (0, 255, 1, int),
            "MIN_AREA": (0, 10000, 50, int),
            "MAX_AREA": (100, 100000, 100, int),
            "CONVERSION_FACTOR": (0.01, 10.0, 0.01, float) # –î–æ–±–∞–≤–∏–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–º
        }

        self.param_widgets = {}

        for name, (min_val, max_val, step, val_type) in param_specs.items():
            value = self.detection_params.get(name, self.DEFAULT_DETECTION_PARAMS.get(name)) # –ë–µ—Ä–µ–º –∏–∑ —Ç–µ–∫—É—â–∏—Ö –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç

            container = QVBoxLayout()
            container.setSpacing(2)

            # 1. Label
            param_label = QLabel(f"{name}:") # –î–æ–±–∞–≤–∏–º –¥–≤–æ–µ—Ç–æ—á–∏–µ
            param_label.setAlignment(Qt.AlignLeft)
            container.addWidget(param_label)

            # 2. Horizontal row: Slider + Value Label
            hbox = QHBoxLayout()
            slider = QSlider(Qt.Horizontal)

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–ª–∞–π–¥–µ—Ä–∞
            if val_type == int:
                slider_min = min_val
                slider_max = max_val
                slider_value = int(value)
                slider.setSingleStep(step if name != "BLUR_KERNEL" else 1) # –û–±—ã—á–Ω—ã–π —à–∞–≥ –¥–ª—è –∏–Ω—Ç
                slider.setTickInterval(step)
            else: # float
                # –î–ª—è float –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å, —á—Ç–æ–±—ã —Å–ª–∞–π–¥–µ—Ä —Ä–∞–±–æ—Ç–∞–ª —Å int
                multiplier = 1 / step
                slider_min = int(min_val * multiplier)
                slider_max = int(max_val * multiplier)
                slider_value = int(value * multiplier)
                slider.setSingleStep(1) # –®–∞–≥ —Å–ª–∞–π–¥–µ—Ä–∞ –≤—Å–µ–≥–¥–∞ 1 –¥–ª—è float

            slider.setMinimum(slider_min)
            slider.setMaximum(slider_max)
            slider.setValue(slider_value)

            value_label = QLabel(f"{value:.2f}" if val_type==float else str(value))
            value_label.setFixedWidth(45) # –ß—É—Ç—å —à–∏—Ä–µ
            value_label.setAlignment(Qt.AlignRight)

            hbox.addWidget(slider, 1) # –°–ª–∞–π–¥–µ—Ä —Ä–∞—Å—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è
            hbox.addWidget(value_label)
            container.addLayout(hbox)


            # –§—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è)
            def update_value(param_name, param_spec, current_slider_val, lbl_widget, slider_widget):
                p_min, p_max, p_step, p_type = param_spec

                if p_type == float:
                    multiplier = 1 / p_step
                    new_val = current_slider_val / multiplier
                else: # int
                    new_val = current_slider_val
                    # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –¥–ª—è BLUR_KERNEL (–¥–µ–ª–∞–µ–º –Ω–µ—á–µ—Ç–Ω—ã–º)
                    if param_name == "BLUR_KERNEL" and new_val % 2 == 0:
                       # –ï—Å–ª–∏ —á–µ—Ç–Ω–æ–µ, –±–µ—Ä–µ–º –±–ª–∏–∂–∞–π—à–µ–µ –Ω–µ—á–µ—Ç–Ω–æ–µ > 0
                       new_val = max(1, new_val - 1)
                       # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º —Å–ª–∞–π–¥–µ—Ä, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–ª–æ—Å—å
                       slider_widget.setValue(new_val)
                       # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è, —á—Ç–æ–±—ã –Ω–µ –æ–±–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —á–µ—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
                       return

                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ min/max
                new_val = max(p_min, min(p_max, new_val))

                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
                formatted_val = f"{new_val:.2f}" if p_type == float else str(new_val)
                display_val = new_val if p_type == int else round(new_val, 2)

                # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                if self.detection_params.get(param_name) != display_val:
                    self.detection_params[param_name] = display_val
                    #print(f"[PARAM] {param_name} set to {display_val}")
                    lbl_widget.setText(formatted_val)
                    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∏–∑–º–µ–Ω–µ–Ω–∏–∏?
                    # self.save_detection_params()


            # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Å–∏–≥–Ω–∞–ª —Å–ª–∞–π–¥–µ—Ä–∞ –∫ —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º partial –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–µ–∏–∑–º–µ–Ω—è–µ–º—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            slider.valueChanged.connect(partial(update_value, name, param_specs[name], lbl_widget=value_label, slider_widget=slider))

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–∂–µ—Ç—ã –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            self.param_widgets[name] = (param_label, value_label, slider)
            panel_layout.addLayout(container)

        panel_layout.addStretch(1) # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—Ç—è–≥–∏–≤–∞—é—â–µ–µ—Å—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –≤–Ω–∏–∑

        # –ö–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Ä—É—á–Ω—É—é
        save_button = QPushButton("Save Params")
        save_button.clicked.connect(self.save_detection_params)
        panel_layout.addWidget(save_button)

        return panel_layout

    # --- –ú–µ—Ç–æ–¥—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è UI ---

    def update_calibration_source_ui(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–∏–¥–∏–º–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
        is_video = self.calib_source_selector.currentText() == "Calibration video"
        self.calib_video_layout_container.setVisible(is_video)
        self.calib_camera_layout_container.setVisible(not is_video)

    def update_working_source_ui(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–∏–¥–∏–º–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–±–æ—á–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
        is_video = self.working_source_selector.currentText() == "Working video"
        self.working_video_layout_container.setVisible(is_video)
        self.working_camera_layout_container.setVisible(not is_video)


    # --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π –∏ –ª–æ–≥–∏–∫–∞ ---

    # Modbus
    def _connect_modbus(self):
        ip = self.modbus_ip_input.text()
        port_text = self.modbus_port_input.text()
        try:
            port = int(port_text)
            if not (0 < port < 65536):
                raise ValueError("Port out of range")
        except ValueError:
            QMessageBox.warning(self, "Input Error", "Invalid Port number. Please enter a number between 1 and 65535.")
            return

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –±—ã–ª–æ
        if self.robot and self.robot.connected:
            self.robot.disconnect()

        self.robot = RobotComm(host=ip, port=port)
        self.robot.connect()

        if self.robot.connected:
            self.modbus_status_label.setText(f"Status: ‚úÖ Connected to {ip}:{port}")
            self.modbus_connect_button.setEnabled(False)
            self.modbus_disconnect_button.setEnabled(True)
            logging.info(f"Successfully connected to Modbus server at {ip}:{port}")
        else:
            self.modbus_status_label.setText("Status: ‚ùå Connection failed")
            QMessageBox.critical(self, "Connection Error", f"Failed to connect to Modbus server at {ip}:{port}.")
            self.modbus_connect_button.setEnabled(True)
            self.modbus_disconnect_button.setEnabled(False)
            logging.error(f"Failed to connect to Modbus server at {ip}:{port}")
            self.robot = None # –£–±–∏—Ä–∞–µ–º –Ω–µ—É–¥–∞—á–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä

    def _disconnect_modbus(self):
        if self.robot and self.robot.connected:
            self.robot.disconnect()
        self.modbus_status_label.setText("Status: üîå Disconnected")
        self.modbus_connect_button.setEnabled(True)
        self.modbus_disconnect_button.setEnabled(False)
        self.robot = None
        logging.info("Disconnected from Modbus server by user.")

    def _scan_network_for_modbus(self):
        subnet = ".".join(self.modbus_ip_input.text().split('.')[:3]) + "." # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 –æ–∫—Ç–µ—Ç–∞ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ IP
        port = int(self.modbus_port_input.text())
        self.modbus_device_selector.clear()
        self.modbus_status_label.setText("Status: Scanning...")
        QApplication.processEvents() # –û–±–Ω–æ–≤–ª—è–µ–º UI –ø–µ—Ä–µ–¥ –¥–æ–ª–≥–∏–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º

        found_ips = []

        def check_ip(ip):
            try:
                with socket.create_connection((ip, port), timeout=0.2): # –£–º–µ–Ω—å—à–∏–º —Ç–∞–π–º–∞—É—Ç
                    return ip
            except (socket.timeout, OSError): # –õ–æ–≤–∏–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
                return None

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(check_ip, f"{subnet}{i}") for i in range(1, 255)]
            for future in futures:
                result = future.result()
                if result:
                    found_ips.append(result)
                    self.modbus_device_selector.addItem(result) # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ –º–µ—Ä–µ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è
                    QApplication.processEvents() # –ü–æ–∑–≤–æ–ª—è–µ–º UI –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è

        if found_ips:
            self.modbus_status_label.setText(f"Status: Scan complete. Found {len(found_ips)} device(s)")
            self.modbus_device_selector.setCurrentIndex(0) # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π
            self.modbus_ip_input.setText(self.modbus_device_selector.currentText()) # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª–µ –≤–≤–æ–¥–∞ IP
        else:
            self.modbus_status_label.setText("Status: Scan complete. No devices found")
            QMessageBox.information(self, "Scan Results", f"No Modbus devices found on subnet {subnet}* at port {port}.")


    # Calibration
    def _browse_calibration_video(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Calibration Video", var.APP_DIR, "Video Files (*.mp4 *.avi *.mov)")
        if file_path:
            self.calib_video_path_input.setText(file_path)
            var.CALIBRATION_VIDEO_PATH = file_path # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (—Å–ø–æ—Ä–Ω–æ, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏–∫—É)
            print(f"Selected calibration video: {file_path}")

    def _update_calibration_camera_index(self):
         try:
            index = int(self.calib_camera_index_input.text())
            if index < 0: raise ValueError("Index must be non-negative")
            var.CAMERA_INDEX = index # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é
            print(f"Updated calibration CAMERA_INDEX to: {index}")
         except ValueError as e:
            QMessageBox.warning(self, "Input Error", f"Invalid Camera Index: {e}. Please enter a non-negative integer.")
            self.calib_camera_index_input.setText(str(var.CAMERA_INDEX)) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ


    def start_calibration(self):
        if self._is_calibrating:
            print("[WARN] Calibration is already running.")
            return

        self._is_calibrating = True
        self._calib_stop_flag = False
        self.calib_start_button.setEnabled(False)
        self.calib_stop_button.setEnabled(True)
        self.calib_video_label.setText("Starting calibration...")
        QApplication.processEvents()


        source = self.calib_source_selector.currentText()
        if source == "Calibration video":
            source_type = "video"
            video_path = self.calib_video_path_input.text()
            camera_index = -1 # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            if not os.path.exists(video_path):
                QMessageBox.critical(self, "File Error", f"Calibration video file not found:\n{video_path}")
                self._cleanup_calibration()
                return
        else: # Camera
            source_type = "camera"
            video_path = None
            try:
                camera_index = int(self.calib_camera_index_input.text())
            except ValueError:
                 QMessageBox.critical(self, "Input Error", "Invalid Camera Index for calibration.")
                 self._cleanup_calibration()
                 return

        # Callbacks –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è GUI –∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        def frame_callback_gui(frame):
            # –≠—Ç–æ—Ç –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –ø–æ—Ç–æ–∫–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏, –æ–±–Ω–æ–≤–ª—è–µ–º QLabel
            try:
                pixmap = Utils.frame_to_qpixmap(frame, self.calib_video_label)
                self.calib_video_label.setPixmap(pixmap)
            except Exception as e:
                print(f"[ERROR] Error updating calibration preview: {e}") # –ù–µ —Ñ–∞—Ç–∞–ª—å–Ω–æ

        def done_callback_gui(camera_matrix, dist_coeffs):
            # –≠—Ç–æ—Ç –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –ø–æ—Ç–æ–∫–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é
            if camera_matrix is not None:
                QMessageBox.information(self, "Calibration Result", "Calibration successful!\nResults saved to " + var.CALIBRATION_FILE)
                print("[INFO] Calibration successful.")
            else:
                 # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—à–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
                if self._calib_stop_flag:
                    QMessageBox.warning(self, "Calibration Result", "Calibration stopped by user.")
                    print("[INFO] Calibration stopped by user.")
                else:
                    QMessageBox.critical(self, "Calibration Result", "Calibration failed or could not gather enough data.")
                    print("[ERROR] Calibration failed.")

            # –í–∞–∂–Ω–æ: –æ–±–Ω–æ–≤–ª—è—Ç—å UI –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            self.parent()._schedule_task(self._cleanup_calibration)


        print(f"[INFO] Starting calibration with source: {source_type} (Index/Path: {camera_index if source_type=='camera' else video_path})")
        # –ó–∞–ø—É—Å–∫ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ
        self._calib_thread = threading.Thread(
            target=calibrate_camera_gui,
            args=(source_type, camera_index, video_path, var.MAX_CAPTURES),
            kwargs={
                'frame_callback': frame_callback_gui,
                'done_callback': done_callback_gui,
                'stop_flag_getter': lambda: self._calib_stop_flag
            },
            daemon=True
        )
        self._calib_thread.start()

    def stop_calibration(self):
        if not self._is_calibrating:
            return
        print("[INFO] Requesting calibration stop...")
        self._calib_stop_flag = True
        # –ü–æ—Ç–æ–∫ —Å–∞–º –∑–∞–≤–µ—Ä—à–∏—Ç—Å—è –∏ –≤—ã–∑–æ–≤–µ—Ç done_callback -> _cleanup_calibration


    def _cleanup_calibration(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è/–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
        print("[INFO] Cleaning up calibration state...")
        self._is_calibrating = False
        self._calib_stop_flag = False # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥
        self.calib_start_button.setEnabled(True)
        self.calib_stop_button.setEnabled(False)
        self.calib_video_label.setText("Calibration preview will appear here")
        self.calib_video_label.setStyleSheet("background-color: black; color: grey;") # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∏–ª—å
        self.calib_thread = None # –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Ç–æ–∫
        QApplication.processEvents() # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å


    # Working Mode
    def _browse_working_video(self):
        file_path, _ = QFileDialog.getOpenFileName(self, "Select Working Video", var.APP_DIR, "Video Files (*.mp4 *.avi *.mov)")
        if file_path:
            self.working_video_path_input.setText(file_path)
            var.WORKING_VIDEO_PATH = file_path # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é
            print(f"Selected working video: {file_path}")

    def _update_working_camera_index(self):
         try:
            index = int(self.working_camera_index_input.text())
            if index < 0: raise ValueError("Index must be non-negative")
            # –ú–æ–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å var.CAMERA_INDEX –∑–¥–µ—Å—å, –µ—Å–ª–∏ —Ö–æ—Ç–∏–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π
            print(f"Updated working CAMERA_INDEX to: {index}")
         except ValueError as e:
            QMessageBox.warning(self, "Input Error", f"Invalid Camera Index: {e}. Please enter a non-negative integer.")
            self.working_camera_index_input.setText(str(var.CAMERA_INDEX)) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é


    def start_working_mode(self):
        if self._is_working:
            print("[WARN] Working mode is already running.")
            return

        # --- 1. –ü—Ä–æ–≤–µ—Ä–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ---
        self.working_start_button.setEnabled(False) # –ë–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É Start —Å—Ä–∞–∑—É

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if not os.path.exists(var.CALIBRATION_FILE):
             QMessageBox.critical(self, "Setup Error", f"Calibration file not found: {var.CALIBRATION_FILE}\nPlease run calibration first.")
             self.working_start_button.setEnabled(True)
             return
        try:
            calib_data = np.load(var.CALIBRATION_FILE)
            cameraMatrix = calib_data['cameraMatrix']
            distCoeffs = calib_data['distCoeffs']
        except Exception as e:
             QMessageBox.critical(self, "Setup Error", f"Error loading calibration data from {var.CALIBRATION_FILE}:\n{e}")
             self.working_start_button.setEnabled(True)
             return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–µ–∫—Ä–∏—Ç–∏—á–Ω–æ, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç)
        identification_config_path = var.IDENTIFICATION_CONFIG
        if not os.path.exists(identification_config_path):
            print(f"[WARN] Identification config {identification_config_path} not found. Recognition might be limited.")
            QMessageBox.warning(self, "Config Warning", f"Identification config file not found:\n{identification_config_path}\nObject recognition might be limited to basic features.")
            # identification_config_path = None # –ú–æ–∂–Ω–æ –∏ —Ç–∞–∫, –Ω–æ ObjectDetector —Å–ø—Ä–∞–≤–∏—Ç—Å—è —Å –ø—É—Ç–µ–º

        # –û—Ç–∫—Ä—ã—Ç–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤–∏–¥–µ–æ
        source = self.working_source_selector.currentText()
        if source == "Working video":
            video_path = self.working_video_path_input.text()
            if not os.path.exists(video_path):
                 QMessageBox.critical(self, "File Error", f"Working video file not found:\n{video_path}")
                 self.working_start_button.setEnabled(True)
                 return
            cap = cv2.VideoCapture(video_path)
        else: # Camera
            try:
                index = int(self.working_camera_index_input.text())
                cap = cv2.VideoCapture(index)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, var.CAMERA_WIDTH)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, var.CAMERA_HEIGHT)
                cap.set(cv2.CAP_PROP_FPS, var.CAMERA_FPS)
            except ValueError:
                QMessageBox.critical(self, "Input Error", "Invalid Camera Index for working mode.")
                self.working_start_button.setEnabled(True)
                return
            except Exception as e:
                 QMessageBox.critical(self, "Camera Error", f"Failed to open camera {index}: {e}")
                 self.working_start_button.setEnabled(True)
                 return

        if not cap.isOpened():
             QMessageBox.critical(self, "Source Error", f"Failed to open video source ({source}).")
             self.working_start_button.setEnabled(True)
             return

        # --- 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ) ---
        self.working_video_label.setText("Detecting working area...")
        QApplication.processEvents()
        working_area_confirmed = False
        max_attempts = 5 # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±–ª–∞—Å—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–∞–¥—Ä–∞—Ö
        attempt = 0
        while attempt < max_attempts and not working_area_confirmed:
            ret, frame = cap.read()
            if not ret:
                 QMessageBox.critical(self, "Source Error", "Failed to read frame from video source to detect working area.")
                 cap.release()
                 self.working_start_button.setEnabled(True)
                 return

            print(f"[INFO] Attempt {attempt+1} to detect working area...")
            # –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–¥–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
            self.working_area_processor.detection_params = self.detection_params
            confirmed = self._prepare_working_area(frame) # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∫–∞–∂–µ—Ç –¥–∏–∞–ª–æ–≥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

            if confirmed is None: # –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
                print("[INFO] Working area not found in this frame.")
                attempt += 1
                continue
            elif confirmed is True: # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª
                working_area_confirmed = True
                print("[INFO] Working area confirmed by user.")
                break
            else: # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–∫–∞–∑–∞–ª—Å—è
                print("[INFO] User rejected the working area. Trying next frame...")
                attempt += 1 # –ü—ã—Ç–∞–µ–º—Å—è —Å–Ω–æ–≤–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –∫–∞–¥—Ä–µ

        if not working_area_confirmed:
            QMessageBox.warning(self, "Setup Failed", "Could not confirm the working area after several attempts. Please check lighting and camera view.")
            cap.release()
            self._cleanup_working_mode() # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –º–µ—Ç–æ–¥ –æ—á–∏—Å—Ç–∫–∏
            return

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∞–∫—Ç–æ—Ä –∫–æ–Ω–≤–µ—Ä—Å–∏–∏, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –Ω–∞–π–¥–µ–Ω
        if "CONVERSION_FACTOR" in self.working_area_processor.detection_params:
             self.detection_params["CONVERSION_FACTOR"] = self.working_area_processor.detection_params["CONVERSION_FACTOR"]
             print(f"[PARAM] Updated CONVERSION_FACTOR from working area: {self.detection_params['CONVERSION_FACTOR']:.4f}")
             # –û–±–Ω–æ–≤–ª—è–µ–º UI —Å–ª–∞–π–¥–µ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
             self._update_param_widget("CONVERSION_FACTOR")

        # --- 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∏ –∑–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ ---
        self._is_working = True
        self._working_stop_flag = False
        self._working_frame_counter = 0
        self._working_records = []

        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        self._detector = ObjectDetector(
            identification_config_path=identification_config_path,
            detection_params=self.detection_params
        )

        self.working_video_label.setText("Working mode started...")
        self.working_stop_button.setEnabled(True) # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É –°—Ç–æ–ø
        QApplication.processEvents()

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫
        self._working_thread = threading.Thread(
            target=self._working_mode_thread_loop,
            args=(cap, cameraMatrix, distCoeffs), # –ü–µ—Ä–µ–¥–∞–µ–º VideoCapture –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
            daemon=True
        )
        self._working_thread.start()


    def stop_working_mode(self):
        if not self._is_working:
            return
        print("[INFO] Requesting working mode stop...")
        self._working_stop_flag = True
        self.working_start_button.setEnabled(False) # –ü–æ–∫–∞ –ø–æ—Ç–æ–∫ –Ω–µ –∑–∞–≤–µ—Ä—à–∏—Ç—Å—è, Start –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        self.working_stop_button.setEnabled(False) # Stop —Ç–æ–∂–µ –±–ª–æ–∫–∏—Ä—É–µ–º –Ω–∞ –≤—Ä–µ–º—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        # –ü–æ—Ç–æ–∫ —Å–∞–º –∑–∞–≤–µ—Ä—à–∏—Ç—Å—è –∏ –≤—ã–∑–æ–≤–µ—Ç _cleanup_working_mode

    def _working_mode_thread_loop(self, cap, cameraMatrix, distCoeffs):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤ –≤ —Ä–∞–±–æ—á–µ–º —Ä–µ–∂–∏–º–µ (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ –ø–æ—Ç–æ–∫–µ)."""
        print("[THREAD] Working mode thread started.")
        frame_errors = 0
        max_frame_errors = 10

        while not self._working_stop_flag:
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–∞–¥—Ä–∞ (–Ω–∞ —Å–ª—É—á–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ GUI)
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –≥–æ–Ω–∫–æ–π –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∏–∑ GUI
            current_detection_params = self.detection_params.copy()
            if self._detector:
                 self._detector.detection_params = current_detection_params

            ret, frame = cap.read()
            if not ret:
                frame_errors += 1
                print(f"[THREAD][WARN] Failed to read frame ({frame_errors}/{max_frame_errors})")
                if frame_errors >= max_frame_errors or not cap.get(cv2.CAP_PROP_POS_FRAMES): # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –∑–∞–∫–æ–Ω—á–∏–ª–æ—Å—å
                   print("[THREAD] Video ended or reached max frame read errors.")
                   break
                time.sleep(0.1) # –ü–∞—É–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ —á—Ç–µ–Ω–∏—è
                continue
            else:
                 frame_errors = 0 # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —É–¥–∞—á–Ω–æ–º —á—Ç–µ–Ω–∏–∏


            # 1. –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–∞–¥—Ä–∞
            corrected_frame = cv2.undistort(frame, cameraMatrix, distCoeffs)

            # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–º
            if self._detector and self.working_area_mask is not None:
                # Process frame –ø–µ—Ä–µ–¥–∞–µ—Ç –∫–æ–ø–∏–∏ detection_params –≤–Ω—É—Ç—Ä—å, —Ç–∞–∫ —á—Ç–æ –Ω–µ —Å—Ç—Ä–∞—à–Ω–æ
                result = self._detector.process_frame(corrected_frame,
                                                      self._working_frame_counter,
                                                      mask=self.working_area_mask,
                                                      mode="work") # –£–∫–∞–∂–µ–º —Ä–µ–∂–∏–º
                if result is None:
                    # print("[THREAD] No objects detected or error in processing.")
                    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ—Å—Ç–æ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞–¥—Ä –±–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏–π
                    display_image = corrected_frame
                    detections = [] # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π
                    edges = np.zeros_like(corrected_frame[:,:,0]) # –ü—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥—Ä–∞–Ω–µ–π
                else:
                    edges, objects_overlayed, detections = result
                    display_image = objects_overlayed # –ö–∞–¥—Ä —Å –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–∫–Ω–∞ –æ—Ç–ª–∞–¥–∫–∏ (–µ—Å–ª–∏ –æ—Ç–∫—Ä—ã—Ç–æ)
                if hasattr(self, 'debug_window') and self.debug_window.isVisible():
                    contours_img = np.zeros_like(display_image) # –°–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≥–æ –∂–µ —Ä–∞–∑–º–µ—Ä–∞
                    raw_contours = [d['contour'] for d in detections] # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç—É—Ä—ã –∏–∑ –¥–µ—Ç–µ–∫—Ü–∏–π
                    # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –∫–æ–Ω—Ç—É—Ä—ã, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–µ–∫—É—â–∏–π —Ñ–∞–∫—Ç–æ—Ä –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–∏–∫—Å–µ–ª–µ–π
                    # –í–∞–∂–Ω–æ: `drawContours` —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–∏–∫—Å–µ–ª—å–Ω—ã–º–∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∫–æ–Ω—Ç—É—Ä–æ–≤, –Ω–µ `_mm`
                    conv_factor = current_detection_params.get("CONVERSION_FACTOR", 1.0)
                    if conv_factor == 0: conv_factor = 1.0 # –ü—Ä–µ–¥–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0

                    pixel_contours = []
                    for det_cont in raw_contours:
                        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ 'contour' –≤ detection —Ö—Ä–∞–Ω–∏—Ç –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã.
                        # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Ç–∞–∫, –Ω—É–∂–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å _mm –æ–±—Ä–∞—Ç–Ω–æ –≤ –ø–∏–∫—Å–µ–ª–∏
                         pixel_contours.append(det_cont) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å

                    if pixel_contours:
                        cv2.drawContours(contours_img, pixel_contours, -1, (0, 255, 0), 1) # –ó–µ–ª–µ–Ω—ã–µ –∫–æ–Ω—Ç—É—Ä—ã

                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ Canny (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
                    # –ú–æ–∂–Ω–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å Canny —Å —Ç–µ–∫—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è DebugWindow
                    gray = cv2.cvtColor(corrected_frame, cv2.COLOR_BGR2GRAY)
                    blur_k = current_detection_params.get("BLUR_KERNEL", 5)
                    blur_k = max(1, blur_k if blur_k % 2 != 0 else blur_k - 1) # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–µ—á–µ—Ç–Ω–æ—Å—Ç—å > 0
                    blur = cv2.GaussianBlur(gray, (blur_k, blur_k), 0)
                    canny_l = current_detection_params.get("CANNY_LOW", 50)
                    canny_h = current_detection_params.get("CANNY_HIGH", 150)
                    debug_canny_edges = cv2.Canny(blur, canny_l, canny_h)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Canny –≤ BGR –¥–ª—è DebugWindow
                    debug_canny_edges_bgr = cv2.cvtColor(debug_canny_edges, cv2.COLOR_GRAY2BGR)


                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º _schedule_task –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –º–µ—Ç–æ–¥–∞ DebugWindow
                    # schedule_task(self.debug_window.update_images, debug_canny_edges_bgr, contours_img)

                    # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–±–µ–∑–æ–ø–∞—Å–µ–Ω, –µ—Å–ª–∏ DebugWindow –¥–µ–ª–∞–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –≤–µ—â–∏)
                    try:
                        # –î–µ–ª–∞–µ–º –∫–æ–ø–∏–∏ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –ø–æ—Ç–æ–∫–∞–º–∏
                        self.debug_window.update_images(debug_canny_edges_bgr.copy(), contours_img.copy())
                    except Exception as e:
                         print(f"[THREAD][WARN] Error updating debug window: {e}")


            else:
                 print("[THREAD][WARN] Detector or working area mask not initialized.")
                 display_image = corrected_frame # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ—Å—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–∞–¥—Ä
                 detections = []


            # 3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ GUI (–æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–¥—Ä–∞)
            # pixmap = Utils.frame_to_qpixmap(display_image, self.working_video_label)
            # Schedule task to update pixmap in the main thread
            # self.parent()._schedule_task(self.working_video_label.setPixmap, pixmap)

            # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ setPixmap –∏–∑ –ø–æ—Ç–æ–∫–∞ (–º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π, –Ω–æ —á–∞—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ PyQt)
            try:
                pixmap = Utils.frame_to_qpixmap(display_image, self.working_video_label)
                self.working_video_label.setPixmap(pixmap)
            except Exception as e:
                print(f"[THREAD][WARN] Error setting pixmap in working mode: {e}")


            # 4. –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –∏ –µ—Å—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º schedule_task –¥–ª—è –≤—ã–∑–æ–≤–∞ send_robot_data –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞? –ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–¥–µ—Å—å?
            # –ü—Ä–æ—â–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä—è–º–æ –∏–∑ —ç—Ç–æ–≥–æ –ø–æ—Ç–æ–∫–∞, RobotComm –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω—ã–º (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ pyModbusTCP –æ–±—ã—á–Ω–æ –¥–∞)

            send_via_modbus = self.modbus_checkbox.isChecked() # –ß–∏—Ç–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–±–æ–∫—Å–∞ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ)

            if send_via_modbus and self.robot and self.robot.is_connected():
                 if detections:
                     self.send_robot_data(detections) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ –≥–ª–∞–≤–Ω–æ–≥–æ –æ–∫–Ω–∞
                 # else:
                     # print("[THREAD] No detections to send via Modbus.")
            elif send_via_modbus:
                if not self.robot or not self.robot.is_connected():
                    # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
                    # if self._working_frame_counter % 60 == 0: # –†–∞–∑ –≤ ~2 —Å–µ–∫—É–Ω–¥—ã –ø—Ä–∏ 30fps
                    #     print("[THREAD][WARN] Modbus sending enabled, but robot is not connected.")
                    pass # –ù–µ —Å–ø–∞–º–∏–º –∫–æ–Ω—Å–æ–ª—å


            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω—Å–æ–ª—å, –µ—Å–ª–∏ Modbus –Ω–µ –≤–∫–ª—é—á–µ–Ω
            if not send_via_modbus and detections:
                 # print(f"--- Frame {self._working_frame_counter} Detections ---")
                 for d in detections:
                    # category = d.get('predicted_category', 'unknown')
                    # center = d.get('center', (0,0))
                    # size = (d.get('width', 0), d.get('height', 0))
                    # track_id = d.get('track_id', -1)
                    # print(f"  ID {track_id} | Cat: {category} | Center(mm): ({center[0]:.1f}, {center[1]:.1f}) | Size(mm): {size[0]:.1f}x{size[1]:.1f}")
                    pass # –ü–æ–∫–∞ –æ—Ç–∫–ª—é—á–∏–º –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å


            self._working_frame_counter += 1
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å CPU –∏ –¥–∞—Ç—å GUI –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å
            time.sleep(0.01)

        # --- –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω (–ª–∏–±–æ stop_flag, –ª–∏–±–æ –æ—à–∏–±–∫–∞) ---
        print("[THREAD] Working mode thread finished.")
        cap.release()
        print("[THREAD] Video capture released.")

        # –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        # self._export_detection_data()

        # –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –æ—á–∏—Å—Ç–∫—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        self.parent()._schedule_task(self._cleanup_working_mode)

    def _cleanup_working_mode(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è/–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞–±–æ—á–µ–≥–æ —Ä–µ–∂–∏–º–∞."""
        print("[INFO] Cleaning up working mode state...")
        self._is_working = False
        self._working_stop_flag = False
        self.working_start_button.setEnabled(True)
        self.working_stop_button.setEnabled(False)
        self.working_video_label.setText("Working mode video will appear here")
        self.working_video_label.setStyleSheet("background-color: black; color: grey;")
        # –°–∫—Ä—ã–≤–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏
        self.working_area_confirm_label.setVisible(False)
        self.working_confirm_layout_widget.setVisible(False)

        self.working_area_mask = None
        self.last_overlay_frame = None
        self._detector = None
        self._working_thread = None # –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Ç–æ–∫
        print("[INFO] Working mode cleanup complete.")
        QApplication.processEvents()

    def send_robot_data(self, detections):
         """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–æ–±–æ—Ç—É."""
         if not self.robot or not self.robot.is_connected():
             # print("[WARN] Attempted to send data, but robot is not connected.")
             return

         # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –º–∞–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ –∫–æ–¥—ã (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ variables.py)
         category_mapping = {
            "circular_white": 1, "circle_white": 1,
            "circular_pink": 2, "circle_red": 2, # –î–æ–ø—É—Å—Ç–∏–º, —Ä–æ–∑–æ–≤—ã–π —ç—Ç–æ –∫—Ä–∞—Å–Ω—ã–π
            "circular_black": 3, "circle_black": 3,
            "rhombus_white": 4, "rectangle_white": 4, # –î–æ–ø—É—Å—Ç–∏–º, —Ä–æ–º–± —ç—Ç–æ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            "rhombus_pink": 5, "rectangle_red": 5,
            "rhombus_black": 6, "rectangle_black": 6,
            # –î–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...
            "unknown": 0,
        }

         for det in detections:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è –¥–µ—Ç–µ–∫—Ü–∏–∏
            x_mm = det.get('center', (0,0))[0]
            y_mm = det.get('center', (0,0))[1]
            width_mm = det.get('width', 0)
            height_mm = det.get('height', 0)
            angle = det.get('angle', 0)
            category_name = det.get('predicted_category', "unknown").lower() # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
            category_code = category_mapping.get(category_name, 0) # 0 –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö/–Ω–µ–Ω–∞–π–¥–µ–Ω–Ω—ã—Ö
            obj_id = det.get('track_id', 0) # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID —Ç—Ä–µ–∫–µ—Ä–∞

            # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ RobotComm
            # print(f"[SEND] ID:{obj_id}, Cat:{category_code}({category_name}), X:{x_mm:.1f}, Y:{y_mm:.1f}, W:{width_mm:.1f}, H:{height_mm:.1f}, Ang:{angle:.1f}")
            success = self.robot.send_data(
                obj_id=obj_id,
                x_mm=x_mm,
                y_mm=y_mm,
                width_mm=width_mm,
                height_mm=height_mm,
                angle=angle,
                category_code=category_code
            )
            if not success:
                 print(f"[ERROR] Failed to send data for object ID {obj_id} via Modbus.")
                 # –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç —Ä–∞–∑–æ—Ä–≤–∞—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–ª–∏ –ø—Ä–µ–¥–ø—Ä–∏–Ω—è—Ç—å –¥—Ä—É–≥–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ

    def confirm_working_area(self, overlay_frame):
        """
        –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—É—é —Ä–∞–±–æ—á—É—é –æ–±–ª–∞—Å—Ç—å –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –°–ò–ù–•–†–û–ù–ù–û –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ GUI. –ë–ª–æ–∫–∏—Ä—É–µ—Ç –≤—ã–∑–≤–∞–≤—à–∏–π –ø–æ—Ç–æ–∫ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ), False (–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ) –∏–ª–∏ None (–æ—à–∏–±–∫–∞/–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ).
        """
        print("[GUI] Showing working area confirmation dialog...")
        self._confirmation_result = None  # –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

        # --- –û–±–Ω–æ–≤–ª—è–µ–º UI –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è ---
        self.working_area_confirm_label.setVisible(True)
        self.working_confirm_layout_widget.setVisible(True)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –∫–∞–¥—Ä
        pixmap = Utils.frame_to_qpixmap(overlay_frame, self.working_video_label)
        self.working_video_label.setPixmap(pixmap)

        # –°–æ–∑–¥–∞–µ–º –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º QEventLoop –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
        loop = QEventLoop()

        # –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–∂–∞—Ç–∏–π –∫–Ω–æ–ø–æ–∫
        def accept_area():
            print("[GUI] User confirmed the working area.")
            self._confirmation_result = True
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UI
            self.working_area_confirm_label.setVisible(False)
            self.working_confirm_layout_widget.setVisible(False)
            loop.quit()

        def reject_area():
            print("[GUI] User rejected the working area.")
            self._confirmation_result = False
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UI
            self.working_area_confirm_label.setVisible(False)
            self.working_confirm_layout_widget.setVisible(False)
            loop.quit()

        # –û—Ç—Å–æ–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–µ—Å–ª–∏ –±—ã–ª–∏) –∏ –ø–æ–¥–∫–ª—é—á–∞–µ–º –Ω–æ–≤—ã–µ
        try:
            self.confirm_button_yes.clicked.disconnect()
            self.confirm_button_no.clicked.disconnect()
        except TypeError: # –°–∏–≥–Ω–∞–ª—ã –Ω–µ –±—ã–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω—ã
             pass
        self.confirm_button_yes.clicked.connect(accept_area)
        self.confirm_button_no.clicked.connect(reject_area)

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π, –∂–¥–µ–º loop.quit()
        loop.exec_()

        print(f"[GUI] Working area confirmation result: {self._confirmation_result}")
        return self._confirmation_result

    def _prepare_working_area(self, frame):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å —Ä–∞–±–æ—á—É—é –æ–±–ª–∞—Å—Ç—å –Ω–∞ –∫–∞–¥—Ä–µ –∏ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ), False (–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º), None (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ).
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –ü–ï–†–ï–î –∑–∞–ø—É—Å–∫–æ–º —Ä–∞–±–æ—á–µ–≥–æ –ø–æ—Ç–æ–∫–∞.
        """
        print("[SETUP] Detecting working area...")
        result = self.working_area_processor.objectDetection(frame)

        if result is None:
            print("[SETUP] Working area not detected in this frame.")
            # –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–∏—á–µ–≥–æ, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
            # –ú–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            # pixmap = Utils.frame_to_qpixmap(frame, self.working_video_label)
            # self.working_video_label.setPixmap(pixmap)
            # QApplication.processEvents()
            return None # –ù–µ –Ω–∞–π–¥–µ–Ω–æ
        else:
            overlay_frame, working_mask, conversion_factor = result
            print(f"[SETUP] Candidate working area found. Conversion factor ~ {conversion_factor:.4f}. Asking for confirmation.")

            # –í—ã–∑—ã–≤–∞–µ–º confirm_working_area, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∫–∞–∂–µ—Ç overlay_frame –∏ –¥–∏–∞–ª–æ–≥
            user_confirmed = self.confirm_working_area(overlay_frame)

            if user_confirmed is True:
                 # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Å–∫—É –∏ –∫–∞–¥—Ä –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –ø–æ–∫–∞–∑–∞
                 self.working_area_mask = working_mask
                 self.last_overlay_frame = overlay_frame
                 # –í–∞–∂–Ω–æ: –û–±–Ω–æ–≤–ª—è–µ–º CONVERSION_FACTOR –≤ *–æ—Å–Ω–æ–≤–Ω–æ–º* —Å–ª–æ–≤–∞—Ä–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                 self.detection_params["CONVERSION_FACTOR"] = conversion_factor
                 print("[SETUP] Working area confirmed and stored.")
                 return True # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ
            elif user_confirmed is False:
                print("[SETUP] User rejected the area.")
                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–∞—Å–∫—É
                self.working_area_mask = None
                self.last_overlay_frame = None
                return False # –û—Ç–∫–ª–æ–Ω–µ–Ω–æ
            else: # user_confirmed is None (–æ—à–∏–±–∫–∞ –≤ –¥–∏–∞–ª–æ–≥–µ?)
                 print("[SETUP][WARN] Confirmation dialog returned an unexpected value.")
                 return None # –°—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫–æ–π / –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–º


    # Parameter Panel related
    def _toggle_debug_window(self, state):
        if state == Qt.Checked:
            if not hasattr(self, 'debug_window') or not self.debug_window:
                self.debug_window = DebugWindow(parent=self) # –ü–µ—Ä–µ–¥–∞–µ–º parent
            self.debug_window.show()
        else:
            if hasattr(self, 'debug_window') and self.debug_window:
                self.debug_window.hide() # –ü—Ä–æ—Å—Ç–æ —Å–∫—Ä—ã–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –∑–∞–Ω–æ–≤–æ

    def _update_param_widget(self, param_name):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤–∏–¥–∂–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (—Å–ª–∞–π–¥–µ—Ä –∏ –ª–µ–π–±–ª) –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ self.detection_params."""
        if param_name in self.param_widgets and param_name in self.detection_params:
            param_label, value_label, slider = self.param_widgets[param_name]
            value = self.detection_params[param_name]

            # –ù–∞—Ö–æ–¥–∏–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (–Ω–µ–º–Ω–æ–≥–æ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –Ω–æ –¥–ª—è —Ä–µ–¥–∫–∏—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –ø–æ–π–¥–µ—Ç)
            param_spec = None
            # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω param_specs –≤ _create_param_controls
            # –ú—ã –º–æ–∂–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ –∫–∞–∫ —á–ª–µ–Ω –∫–ª–∞—Å—Å–∞ self.param_specs
            if hasattr(self, 'param_specs') and param_name in self.param_specs:
                 param_spec = self.param_specs[param_name]
            else: # –ï—Å–ª–∏ specs –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, –ø–æ–ø—ã—Ç–∞–µ–º—Å—è —É–≥–∞–¥–∞—Ç—å —Ç–∏–ø
                 if isinstance(value, float): p_type = float; p_step=0.01
                 else: p_type=int; p_step=1
                 if param_name == "BLUR_KERNEL": p_step = 2
                 # –ó–Ω–∞—á–µ–Ω–∏—è min/max –∏ step —Ç—É—Ç –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω—ã, —Ç–æ–ª—å–∫–æ —Ç–∏–ø
                 param_spec = (0, 100, p_step, p_type) # Dummy spec

            p_min, p_max, p_step, p_type = param_spec

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Label
            formatted_val = f"{value:.2f}" if p_type == float else str(value)
            value_label.setText(formatted_val)

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Slider
            try:
                if p_type == float:
                    multiplier = 1.0 / p_step
                    slider_value = int(value * multiplier)
                else: # int
                    slider_value = int(value)
                # –û—Ç–∫–ª—é—á–∞–µ–º —Å–∏–≥–Ω–∞–ª—ã —Å–ª–∞–π–¥–µ—Ä–∞ –Ω–∞ –≤—Ä–µ–º—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ä–µ–∫—É—Ä—Å–∏–∏/–ø–µ—Ç–ª–∏
                slider.blockSignals(True)
                slider.setValue(slider_value)
                slider.blockSignals(False)
            except Exception as e:
                print(f"[ERROR] Failed to update slider for {param_name}: {e}")

    def save_detection_params(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –≤ JSON —Ñ–∞–π–ª."""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ DEFAULT_DETECTION_PARAMS
            params_to_save = {k: self.detection_params.get(k, self.DEFAULT_DETECTION_PARAMS[k])
                              for k in self.DEFAULT_DETECTION_PARAMS}

            with open(var.PARAMETERS_CONFIG, "w") as f:
                json.dump(params_to_save, f, indent=4) # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç—Å—Ç—É–ø 4 –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            print(f"[SAVE] Detection parameters saved to {var.PARAMETERS_CONFIG}")
            logging.info(f"Detection parameters saved to {var.PARAMETERS_CONFIG}")
        except Exception as e:
            error_msg = f"Failed to save detection parameters to {var.PARAMETERS_CONFIG}:\n{e}"
            print(f"[ERROR] {error_msg}")
            QMessageBox.critical(self, "Save Error", error_msg)
            logging.error(error_msg)


    def closeEvent(self, event):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏—è –∑–∞–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞."""
        print("Shutting down application...")
        logging.info("Application shutdown sequence started.")

        # 1. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
        if self._is_working:
            print("Stopping working mode...")
            self._working_stop_flag = True
            if self._working_thread and self._working_thread.is_alive():
                print("Waiting for working thread to finish...")
                self._working_thread.join(timeout=2.0) # –î–∞–µ–º –ø–æ—Ç–æ–∫—É –≤—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è
                if self._working_thread.is_alive():
                    print("[WARN] Working thread did not finish cleanly.")
                    logging.warning("Working thread did not finish cleanly on shutdown.")
            print("Working mode stopped.")

        if self._is_calibrating:
            print("Stopping calibration...")
            self._calib_stop_flag = True
            if self._calib_thread and self._calib_thread.is_alive():
                print("Waiting for calibration thread to finish...")
                self._calib_thread.join(timeout=2.0)
                if self._calib_thread.is_alive():
                    print("[WARN] Calibration thread did not finish cleanly.")
                    logging.warning("Calibration thread did not finish cleanly on shutdown.")
            print("Calibration stopped.")

        # 2. –û—Ç–∫–ª—é—á–∞–µ–º—Å—è –æ—Ç —Ä–æ–±–æ—Ç–∞
        if self.robot and self.robot.is_connected():
            print("Disconnecting from Modbus robot...")
            self.robot.disconnect()
            print("Disconnected.")

        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        print("Saving detection parameters...")
        self.save_detection_params()

        # 4. –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ –æ—Ç–ª–∞–¥–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏ –≤–∏–¥–∏–º–æ)
        if hasattr(self, 'debug_window') and self.debug_window:
             print("Closing debug window...")
             self.debug_window.close()


        print("Shutdown complete. Exiting.")
        logging.info("Application shutdown sequence complete.")
        event.accept()

    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ GUI
    # –ù—É–∂–Ω–∞, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ GUI –º–µ—Ç–æ–¥–æ–≤ –∏–∑ –¥—Ä—É–≥–∏—Ö –ø–æ—Ç–æ–∫–æ–≤
    # –í–º–µ—Å—Ç–æ schedule_task –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Qt Signals/Slots –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

    # –ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ schedule_task (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)
    # from PyQt5.QtCore import QTimer
    # def _schedule_task(self, func, *args, **kwargs):
    #      """ –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é func –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ GUI """
    #      QTimer.singleShot(0, lambda: func(*args, **kwargs))



if __name__ == '__main__':
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if not os.path.exists(var.APP_DIR):
        try:
            os.makedirs(var.APP_DIR)
            print(f"Created application data directory: {var.APP_DIR}")
        except OSError as e:
            print(f"Error creating directory {var.APP_DIR}: {e}")
            sys.exit(1) # –í—ã—Ö–æ–¥, –µ—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é

    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec_())
```

**`debug_window.py`** (–í—ã–Ω–µ—Å–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å `DebugWindow`)

```python
# debug_window.py
import cv2
import numpy as np
from PyQt5.QtWidgets import QWidget, QHBoxLayout, QLabel
from PyQt5.QtCore import Qt
from PyQt5.QtGui import QImage, QPixmap

from utils import Utils # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —É—Ç–∏–ª–∏—Ç—É

class DebugWindow(QWidget):
    """–û–∫–Ω–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (Canny, –∫–æ–Ω—Ç—É—Ä—ã)."""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Detection Debug View")
        self.setMinimumSize(640, 320)
        self.resize(800, 400) # –£—Å—Ç–∞–Ω–æ–≤–∏–º —Ä–∞–∑–º–µ—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        layout = QHBoxLayout(self)

        self.canny_label = QLabel("Canny Edges")
        self.canny_label.setAlignment(Qt.AlignCenter)
        self.canny_label.setStyleSheet("background-color: #333; color: white;")
        self.canny_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)

        self.contour_label = QLabel("Detected Contours")
        self.contour_label.setAlignment(Qt.AlignCenter)
        self.contour_label.setStyleSheet("background-color: #333; color: white;")
        self.contour_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)

        layout.addWidget(self.canny_label)
        layout.addWidget(self.contour_label)

        self.canny_image = None
        self.contour_image = None

    def update_images(self, canny_img, contour_img):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        # –î–µ–ª–∞–µ–º –∫–æ–ø–∏–∏ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—ã –º–µ–Ω—è—é—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º –ø–æ—Ç–æ–∫–µ
        self.canny_image = canny_img.copy() if canny_img is not None else None
        self.contour_image = contour_img.copy() if contour_img is not None else None
        self._update_display() # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ

    def _update_display(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç QPixmap –≤ QLabel –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
        if not self.isVisible(): # –ù–µ –æ–±–Ω–æ–≤–ª—è–µ–º, –µ—Å–ª–∏ –æ–∫–Ω–æ —Å–∫—Ä—ã—Ç–æ
            return

        if self.canny_image is not None:
            try:
                pixmap_canny = Utils.frame_to_qpixmap(self.canny_image, self.canny_label)
                self.canny_label.setPixmap(pixmap_canny)
            except Exception as e:
                print(f"[DebugWindow][ERROR] Failed to update Canny image: {e}")
                self.canny_label.setText("Error Canny")
        else:
            self.canny_label.setText("No Canny Image")

        if self.contour_image is not None:
            try:
                pixmap_contour = Utils.frame_to_qpixmap(self.contour_image, self.contour_label)
                self.contour_label.setPixmap(pixmap_contour)
            except Exception as e:
                print(f"[DebugWindow][ERROR] Failed to update Contour image: {e}")
                self.contour_label.setText("Error Contours")
        else:
            self.contour_label.setText("No Contour Image")

    def resizeEvent(self, event):
        """–ü–µ—Ä–µ—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞."""
        self._update_display()
        super().resizeEvent(event)

    def closeEvent(self, event):
        """–°—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –æ–∫–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ 'X')."""
        # –ü—Ä–æ—Å—Ç–æ —Å–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ, –∞ –Ω–µ —É–¥–∞–ª—è–µ–º, –µ—Å–ª–∏ –æ–Ω–æ —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∏–∑ MainWindow
        self.hide()
        event.ignore() # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ, —á—Ç–æ–±—ã MainWindow –º–æ–≥ —É–ø—Ä–∞–≤–ª—è—Ç—å –∏–º

        # –ï—Å–ª–∏ –æ–∫–Ω–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–Ω–∏—á—Ç–æ–∂–µ–Ω–æ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏,
        # –Ω—É–∂–Ω–æ —Å–æ–æ–±—â–∏—Ç—å MainWindow (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ —Å–∏–≥–Ω–∞–ª),
        # —á—Ç–æ–±—ã –æ–Ω —Å–±—Ä–æ—Å–∏–ª self.debug_window = None
```

**`utils.py`** (–ù–æ–≤—ã–π —Ñ–∞–π–ª –¥–ª—è —É—Ç–∏–ª–∏—Ç)

```python
# utils.py
import cv2
import numpy as np
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtWidgets import QWidget, QLabel, QHBoxLayout, QVBoxLayout, QLayout

class Utils:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å —Å –æ–±—â–∏–º–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏."""

    @staticmethod
    def frame_to_qpixmap(frame: np.ndarray, target_widget: QWidget) -> QPixmap:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∫–∞–¥—Ä OpenCV (BGR) –≤ QPixmap, –º–∞—Å—à—Ç–∞–±–∏—Ä—É—è –µ–≥–æ
        –¥–ª—è –≤–ø–∏—Å—ã–≤–∞–Ω–∏—è –≤ target_widget —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π.

        :param frame: –ö–∞–¥—Ä OpenCV (numpy array, BGR).
        :param target_widget: –í–∏–¥–∂–µ—Ç PyQt (–Ω–∞–ø—Ä–∏–º–µ—Ä, QLabel), –≤ –∫–æ—Ç–æ—Ä—ã–π –≤–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.
        :return: QPixmap –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        """
        if frame is None or frame.size == 0:
            return QPixmap() # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π Pixmap, –µ—Å–ª–∏ –∫–∞–¥—Ä –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π

        try:
            frame_h, frame_w = frame.shape[:2]
            label_w = target_widget.width()
            label_h = target_widget.height()

            if frame_h == 0 or frame_w == 0 or label_w <= 0 or label_h <= 0:
                 return QPixmap() # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            scale = min(label_w / frame_w, label_h / frame_h)
            new_w = int(frame_w * scale)
            new_h = int(frame_h * scale)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π –Ω—É–ª–µ–≤—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–æ—Å–ª–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            if new_w <= 0 or new_h <= 0:
                 return QPixmap()

            resized_frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_AREA)

            # –°–æ–∑–¥–∞–Ω–∏–µ QImage
            if len(resized_frame.shape) == 3: # –¶–≤–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (BGR)
                rgb_image = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb_image.shape
                bytes_per_line = ch * w
                q_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)
            elif len(resized_frame.shape) == 2: # –°–µ—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                h, w = resized_frame.shape
                bytes_per_line = w
                q_image = QImage(resized_frame.data, w, h, bytes_per_line, QImage.Format_Grayscale8)
            else:
                return QPixmap() # –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç

            # –°–æ–∑–¥–∞–Ω–∏–µ —á–µ—Ä–Ω–æ–≥–æ —Ö–æ–ª—Å—Ç–∞ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
            canvas = QImage(label_w, label_h, QImage.Format_RGB888)
            canvas.fill(Qt.black)

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–º–µ—â–µ–Ω–∏–µ –¥–ª—è —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏—è
            x_offset = (label_w - new_w) // 2
            y_offset = (label_h - new_h) // 2

            # –†–∏—Å—É–µ–º –æ—Ç–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Ö–æ–ª—Å—Ç–µ (—Ç—Ä–µ–±—É–µ—Ç QPainter)
            from PyQt5.QtGui import QPainter
            painter = QPainter(canvas)
            painter.drawImage(x_offset, y_offset, q_image)
            painter.end()


            return QPixmap.fromImage(canvas)

        except Exception as e:
            print(f"[ERROR] Failed to convert frame to QPixmap: {e}")
            return QPixmap() # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π Pixmap –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

    @staticmethod
    def toggle_layout_visibility(layout: QLayout, visible: bool):
            """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–º–µ–Ω—è–µ—Ç –≤–∏–¥–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –≤–∏–¥–∂–µ—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –º–∞–∫–µ—Ç–∞."""
            if layout is None:
                return
            for i in range(layout.count()):
                item = layout.itemAt(i)
                widget = item.widget()
                sub_layout = item.layout()

                if widget is not None:
                    widget.setVisible(visible)
                elif sub_layout is not None:
                    Utils.toggle_layout_visibility(sub_layout, visible)

```

**`ultimate.py` (–ù–µ–±–æ–ª—å—à–∏–µ –ø—Ä–∞–≤–∫–∏)**

```python
# ultimate.py (—Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –ø—Ä–∞–≤–∫–∞–º–∏)
import cv2
import numpy as np
# import random # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
import math
import pandas as pd
import json
import os
from scipy.optimize import linear_sum_assignment
# from PyQt5.QtWidgets import QMessageBox # QMessageBox –ª—É—á—à–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∏–∑ GUI –ø–æ—Ç–æ–∫–∞ (main.py)
import variables as var # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Å–µ–≤–¥–æ–Ω–∏–º var

# –§—É–Ω–∫—Ü–∏—è –≤—ã–Ω–µ—Å–µ–Ω–∞ –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def undistort_frame(frame, calibration_file=var.CALIBRATION_FILE):
    """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –¥–∏—Å—Ç–æ—Ä—Å–∏—é –∫–∞–¥—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏."""
    if not os.path.exists(calibration_file):
        print(f"[WARN] Calibration file not found: {calibration_file}. Returning original frame.")
        return frame

    try:
        data = np.load(calibration_file)
        cameraMatrix = data['cameraMatrix']
        distCoeffs = data['distCoeffs']
        # print("Calibration data loaded for undistortion.") # –£–º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ–≥–æ–≤
    except Exception as e:
        print(f"[ERROR] Error loading calibration data from {calibration_file}: {e}")
        return frame # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä –ø—Ä–∏ –æ—à–∏–±–∫–µ

    if cameraMatrix is not None and distCoeffs is not None:
        try:
            return cv2.undistort(frame, cameraMatrix, distCoeffs)
        except Exception as e:
             print(f"[ERROR] Error during cv2.undistort: {e}")
             return frame
    else:
         print("[WARN] cameraMatrix or distCoeffs are None in calibration file.")
         return frame


class WorkingArea:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏."""
    def __init__(self,
                 detection_params, # –û–∂–∏–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                 calibration_file=var.CALIBRATION_FILE,
                 confirmation_callback=None, # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (–≤ GUI)
                 parent=None): # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –≤–∏–¥–∂–µ—Ç (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—ã–µ
        self.detection_params = detection_params.copy() if detection_params else {}
        self.calibration_file = calibration_file
        self.confirmation_callback = confirmation_callback
        self.parent = parent
        print("[WorkingArea] Initialized.")

    def objectDetection(self, frame):
        """
        –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é —Ä–∞–±–æ—á—É—é –æ–±–ª–∞—Å—Ç—å –Ω–∞ –∫–∞–¥—Ä–µ.

        :param frame: –í—Ö–æ–¥–Ω–æ–π –∫–∞–¥—Ä (BGR).
        :return: –ö–æ—Ä—Ç–µ–∂ (overlay_frame, working_mask, conversion_factor) –ø—Ä–∏ —É—Å–ø–µ—Ö–µ,
                 None, –µ—Å–ª–∏ –æ–±–ª–∞—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º.
        """
        print("[WorkingArea] Detecting candidate working area...")
        if frame is None:
            print("[WorkingArea][ERROR] Input frame is None.")
            return None

        try:
            corrected_frame = undistort_frame(frame, self.calibration_file)
            if corrected_frame is None: # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏ –∏–∑ undistort_frame
                 corrected_frame = frame # –ü—Ä–æ–±—É–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è self.detection_params
            blur_kernel = self.detection_params.get("BLUR_KERNEL", 5)
             # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–µ—á–µ—Ç–Ω–æ—Å—Ç—å –∏ >= 1
            blur_kernel = max(1, blur_kernel if blur_kernel % 2 != 0 else blur_kernel - 1)
            canny_low = self.detection_params.get("CANNY_LOW", 50)
            canny_high = self.detection_params.get("CANNY_HIGH", 150)

            gray = cv2.cvtColor(corrected_frame, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(gray, (blur_kernel, blur_kernel), 0)
            edges = cv2.Canny(blur, canny_low, canny_high)
            # print("[WorkingArea] Preprocessing (undistort, blur, canny) done.")

            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            print(f"[WorkingArea] Found {len(contours)} raw contours.")

            frame_height, frame_width = corrected_frame.shape[:2]
            min_frame_dim = min(frame_width, frame_height)
            max_frame_dim = max(frame_width, frame_height)
            min_ratio = var.WORKING_AREA_MIN_SIZE_RATIO
            max_ratio = var.WORKING_AREA_MAX_SIZE_RATIO

            candidate_found = False
            for cnt in contours:
                # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–ª–æ—â–∞–¥–∏ –ø–µ—Ä–µ–¥ –¥–æ—Ä–æ–≥–æ–π minAreaRect
                area = cv2.contourArea(cnt)
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–æ–Ω—Ç—É—Ä—ã —Å—Ä–∞–∑—É
                # (–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –ø–ª–æ—â–∞–¥–∏ –∫–∞–¥—Ä–∞ –∫–∞–∫ —ç–≤—Ä–∏—Å—Ç–∏–∫—É)
                if area < (min_frame_dim * max_frame_dim * 0.01): # –ù–∞–ø—Ä–∏–º–µ—Ä, –º–µ–Ω—å—à–µ 1% –ø–ª–æ—â–∞–¥–∏ –∫–∞–¥—Ä–∞
                     continue

                try:
                    rect = cv2.minAreaRect(cnt)
                except Exception as e:
                    print(f"[WorkingArea][WARN] cv2.minAreaRect failed for a contour: {e}")
                    continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –∫–æ–Ω—Ç—É—Ä

                (cx, cy), (width, height), angle = rect

                # –ó–∞—â–∏—Ç–∞ –æ—Ç –Ω—É–ª–µ–≤—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
                if width <= 0 or height <= 0:
                    continue

                short_side, long_side = sorted([width, height])

                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
                short_ratio = short_side / min_frame_dim
                long_ratio = long_side / max_frame_dim
                # print(f"[WorkingArea DEBUG] Candidate: Area={area:.0f}, Short={short_side:.1f} ({short_ratio:.2f}), Long={long_side:.1f} ({long_ratio:.2f}), Angle={angle:.1f}")


                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–π —Å—Ç–æ—Ä–æ–Ω –∫ —Ä–∞–∑–º–µ—Ä–∞–º –∫–∞–¥—Ä–∞
                if (min_ratio <= short_ratio <= max_ratio and
                    min_ratio <= long_ratio <= max_ratio):
                    print(f"[WorkingArea] ‚úÖ Found candidate passing ratio check (Area: {area:.0f}px)")
                    candidate_found = True

                    box = cv2.boxPoints(rect).astype(np.int32)
                    workArea_overlay = corrected_frame.copy()
                    cv2.drawContours(workArea_overlay, [box], 0, (0, 0, 255), 3) # –†–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω—ã–º –∏ –ø–æ—Ç–æ–ª—â–µ

                    # –í—ã–∑—ã–≤–∞–µ–º callback –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
                    # –≠—Ç–æ—Ç callback –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ GUI –∏ –∑–∞–ø—É—Å–∫–∞—Ç—å confirm_working_area
                    user_confirmed = self.confirmation_callback(workArea_overlay) if self.confirmation_callback else True

                    if user_confirmed:
                        print("[WorkingArea] ‚úÖ User confirmed the area.")
                        working_mask = np.zeros(corrected_frame.shape[:2], dtype="uint8")
                        cv2.drawContours(working_mask, [box], 0, 255, -1) # –ó–∞–ª–∏—Ç–∞—è –º–∞—Å–∫–∞

                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ò–ó–í–ï–°–¢–ù–û–ô —à–∏—Ä–∏–Ω—ã –æ–±—ä–µ–∫—Ç–∞ (A4?)
                        # –∏–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–¥–Ω–æ–≥–æ –∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–∞ —ç—Ç–∞–ª–æ–Ω–Ω–∞—è
                        # –í –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ –±—ã–ª–æ 210.0 / short_side - —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ A4 —à–∏—Ä–∏–Ω—É
                        # –û—Å—Ç–∞–≤–∏–º —ç—Ç—É –ª–æ–≥–∏–∫—É, –Ω–æ —Å–¥–µ–ª–∞–µ–º REFERENCE_OBJECT_WIDTH_MM –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º
                        conversion_factor = var.REFERENCE_OBJECT_WIDTH_MM / short_side
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–∫—Ç–æ—Ä –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö —Å–∞–º–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ WorkingArea
                        # –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –ø–æ—Ç–æ–º —Å–∫–æ–ø–∏—Ä—É–µ—Ç –µ–≥–æ –≤ —Å–≤–æ–∏ detection_params
                        self.detection_params["CONVERSION_FACTOR"] = conversion_factor
                        print(f"[WorkingArea] Calculated Conversion Factor: {conversion_factor:.4f} (RefWidth={var.REFERENCE_OBJECT_WIDTH_MM} / FoundShortSide={short_side:.2f})")

                        return workArea_overlay, working_mask, conversion_factor
                    else:
                        print("[WorkingArea] User rejected candidate area. Continuing search...")
                        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Å–∫–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –ø–æ–¥—Ö–æ–¥—è—â–∏–π –∫–æ–Ω—Ç—É—Ä
                # else:
                     # print(f"[WorkingArea DEBUG] Candidate failed ratio check: short_r={short_ratio:.2f}, long_r={long_ratio:.2f}")


            if not candidate_found:
                 print("[WorkingArea] No suitable candidate working area found after checking all contours.")
            return None # –ù–∏—á–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ

        except Exception as e:
            print(f"[WorkingArea][ERROR] Unexpected error during working area detection: {e}")
            import traceback
            traceback.print_exc()
            return None

class ObjectDetector:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞ –æ–±—ä–µ–∫—Ç–æ–≤."""
    def __init__(self, identification_config_path=None,
                 detection_params=None, # –û–∂–∏–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                 confirmation_callback=None, # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–¥–µ—Å—å –Ω–∞–ø—Ä—è–º—É—é
                 parent=None):

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        self.detection_params = detection_params.copy() if detection_params else {}
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–ª—é—á–µ–π, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        # self.detection_params.setdefault("SOME_KEY", default_value)

        self.parent = parent # –°—Å—ã–ª–∫–∞ –Ω–∞ GUI (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–¥–µ—Å—å)
        self.records = [] # –°–ø–∏—Å–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö –≤ CSV
        self.next_track_id = 1
        self.tracks = [] # –ê–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤: {'id': int, 'last_center': tuple(mm), 'lost_frames': int, 'object_name': str}
        self.IDENTIFICATION_CONFIG = {} # { category_name: { parameters: { feature: {min, max}}, ... } }
        self.features_list = [] # –°–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Ñ–∏—á, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.mask = None # –ú–∞—Å–∫–∞ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑–≤–Ω–µ)
        self.calibration_file = var.CALIBRATION_FILE # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        self.MAX_TRACK_LOST_FRAMES = var.MAX_LOST_FRAMES # –°–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ —Ç—Ä–µ–∫ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ—Ç–µ—Ä—è–Ω
        self.MAX_DISTANCE_FOR_TRACKING = var.MAX_DISTANCE # –ú–∞–∫—Å. —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Å–≤—è–∑–∏ —Ç—Ä–µ–∫–∞ (–≤ –º–º!)


        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self._load_identification_config(identification_config_path)
        print("[ObjectDetector] Initialized.")


    def _load_identification_config(self, config_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ JSON."""
        self.IDENTIFICATION_CONFIG = {}
        self.features_list = []
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, "r") as f:
                    data = json.load(f)
                    self.IDENTIFICATION_CONFIG = data.get("categories", {})
                    self.features_list = data.get("features", [])
                    # –ú–∞—Å–∫—É –∏–∑ —ç—Ç–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞ –±–æ–ª—å—à–µ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º, –æ–Ω–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –≤ process_frame
                    print(f"[ObjectDetector] Loaded identification config from: {config_path}")
                    print(f"  - Categories loaded: {list(self.IDENTIFICATION_CONFIG.keys())}")
                    print(f"  - Features for recognition: {self.features_list}")
            except Exception as e:
                print(f"[ObjectDetector][ERROR] Failed to load identification config from {config_path}: {e}")
        else:
            print(f"[ObjectDetector][WARN] Identification config path not provided or file not found: {config_path}. Recognition might be basic.")


    def process_frame(self, corrected_frame, frame_counter, mask=None, mode="work"):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞: –¥–µ—Ç–µ–∫—Ü–∏—è, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ, —Ç—Ä–µ–∫–∏–Ω–≥.

        :param corrected_frame: –ö–∞–¥—Ä –ø–æ—Å–ª–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–∏—Å—Ç–æ—Ä—Å–∏–∏ (BGR).
        :param frame_counter: –ù–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞.
        :param mask: –ë–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ (numpy uint8).
        :param mode: –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã ('work', 'test', 'collect'). –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–∫–∞.
        :return: –ö–æ—Ä—Ç–µ–∂ (edges_image, objects_overlayed_image, list_of_detections) –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
                 list_of_detections: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –æ–ø–∏—Å—ã–≤–∞—é—â–∏—Ö –∫–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç.
        """
        if corrected_frame is None:
            print("[ObjectDetector][ERROR] Input frame is None.")
            return None
        if mask is None:
            print("[ObjectDetector][WARN] No working area mask provided! Processing the whole frame.")
            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É, –ø–æ–∫—Ä—ã–≤–∞—é—â—É—é –≤–µ—Å—å –∫–∞–¥—Ä
            mask_to_use = np.ones(corrected_frame.shape[:2], dtype=np.uint8) * 255
        else:
            mask_to_use = mask

        try:
            # --- 1. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ---
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è self.detection_params (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—ã–∑–æ–≤–∞)
            blur_kernel = self.detection_params.get("BLUR_KERNEL", 5)
            blur_kernel = max(1, blur_kernel if blur_kernel % 2 != 0 else blur_kernel - 1)
            canny_low = self.detection_params.get("CANNY_LOW", 50)
            canny_high = self.detection_params.get("CANNY_HIGH", 150)
            min_area = self.detection_params.get("MIN_AREA", 100)
            max_area = self.detection_params.get("MAX_AREA", 10000)
             # !!! –ü–æ–ª—É—á–∞–µ–º –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏ –ü–ò–ö–°–ï–õ–ï–ô –≤ –ú–ú !!!
            conv = self.detection_params.get("CONVERSION_FACTOR", 1.0)
            if conv <= 0:
                 print(f"[ObjectDetector][WARN] Invalid CONVERSION_FACTOR ({conv}), using 1.0")
                 conv = 1.0

            gray = cv2.cvtColor(corrected_frame, cv2.COLOR_BGR2GRAY)
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –î–û –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç—É—Ä–æ–≤
            gray_masked = cv2.bitwise_and(gray, gray, mask=mask_to_use)
            blur = cv2.GaussianBlur(gray_masked, (blur_kernel, blur_kernel), 0)
            edges = cv2.Canny(blur, canny_low, canny_high)
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)


            # --- 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç—É—Ä–æ–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ---
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã –ø–æ –ø–ª–æ—â–∞–¥–∏ –î–û –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ
            potential_contours = []
            for cnt in contours:
                area_px = cv2.contourArea(cnt)
                if min_area <= area_px <= max_area:
                     potential_contours.append(cnt)
                # else:
                #     print(f"[DEBUG] Contour rejected by area: {area_px} (Min: {min_area}, Max: {max_area})")


            detections = [] # –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π —ç—Ç–æ–≥–æ –∫–∞–¥—Ä–∞
            # processed_centers = set() # –î–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –±–ª–∏–∑–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–ø—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)

            if not potential_contours:
                # print("[ObjectDetector] No contours passed area filter.")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä –∏ –ø—É—Å—Ç—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏, –Ω–æ –Ω–µ None
                overlay_frame = corrected_frame.copy()
                cv2.putText(overlay_frame, f"Frame: {frame_counter} (No detections)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)
                return edges, overlay_frame, []

            print(f"[ObjectDetector] Frame {frame_counter}: {len(potential_contours)} contours passed area filter.")

            for contour in potential_contours:
                try:
                    rect = cv2.minAreaRect(contour) # ((center_x, center_y), (width, height), angle) in pixels
                except Exception as e:
                    print(f"[ObjectDetector][WARN] cv2.minAreaRect failed for a contour: {e}")
                    continue

                center_px = self._get_center_pixels(rect)
                width_px, height_px = rect[1]
                angle = rect[2] # –£–≥–æ–ª –≤ –≥—Ä–∞–¥—É—Å–∞—Ö

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω—É–ª–µ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã
                if width_px <= 0 or height_px <= 0:
                     continue

                # --- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–∏—Ö –∫–æ–Ω—Ç—É—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ---
                # is_duplicate = False
                # for existing_center in processed_centers:
                #      dist = math.dist(center_px, existing_center)
                #      if dist < 10: # –ï—Å–ª–∏ —Ü–µ–Ω—Ç—Ä—ã –±–ª–∏–∂–µ 10 –ø–∏–∫—Å–µ–ª–µ–π - —Å—á–∏—Ç–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–º
                #           is_duplicate = True
                #           break
                # if is_duplicate:
                #      # print(f"[DEBUG] Duplicate contour rejected near {center_px}")
                #      continue
                # processed_centers.add(center_px)

                # --- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---
                features_px = self.compute_shape_features(contour, rect)
                avg_color_bgr = self.compute_average_color(corrected_frame, contour, mask_to_use)

                # –ù–æ—Ä–º–∞ Hu –º–æ–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                hu_norm = np.linalg.norm(np.array(features_px["hu_moments"]))
                # –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∫–∞–Ω–∞–ª –∏–ª–∏ –≤—Å–µ)
                avg_color_val = np.mean(avg_color_bgr)

                # --- –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –ú–ú ---
                # –¶–µ–Ω—Ç—Ä
                center_mm = (center_px[0] * conv, center_px[1] * conv)
                # –†–∞–∑–º–µ—Ä—ã
                width_mm = width_px * conv
                height_mm = height_px * conv
                # –ü–ª–æ—â–∞–¥—å –∏ –ø–µ—Ä–∏–º–µ—Ç—Ä
                area_mm2 = features_px["area"] * (conv ** 2)
                perimeter_mm = features_px["perimeter"] * conv
                # –ì–ª—É–±–∏–Ω–∞ –¥–µ—Ñ–µ–∫—Ç–æ–≤
                avg_defect_depth_mm = features_px["avg_defect_depth"] * conv


                # --- –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è ---
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Ñ–∏—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ features_list –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                features_for_recognition = {
                    "aspect_ratio": features_px["aspect_ratio"], # –î–æ–±–∞–≤–∏–º –≤ compute_shape_features
                    "area": area_mm2, # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–º^2 –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è? –ò–ª–∏ –ø–∏–∫—Å–µ–ª–∏? –ó–ê–í–ò–°–ò–¢ –û–¢ –ö–û–ù–§–ò–ì–ê
                    "perimeter": perimeter_mm, # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ - –º–º –∏–ª–∏ –ø–∏–∫—Å–µ–ª–∏?
                    "extent": features_px["extent"],
                    "hu_moments_norm": hu_norm,
                    "circularity": features_px["circularity"],
                    "convexity_defects_count": features_px["convexity_defects_count"],
                    "avg_defect_depth": avg_defect_depth_mm, # –º–º –∏–ª–∏ –ø–∏–∫—Å–µ–ª–∏?
                    "avg_color_val": avg_color_val # –ó–Ω–∞—á–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ (0-255)
                }

                # --- –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ---
                predicted_category = self._recognize_object(features_for_recognition)
                if predicted_category is None:
                    predicted_category = "unknown"

                # --- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–µ—Ç–µ–∫—Ü–∏–∏ ---
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –ø–∏–∫—Å–µ–ª—å–Ω—ã–µ, —Ç–∞–∫ –∏ –º–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
                detection = {
                    'frame': frame_counter,
                    'center_px': center_px,
                    'width_px': width_px,
                    'height_px': height_px,
                    'center': center_mm, # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –º–º (–æ—Å–Ω–æ–≤–Ω—ã–µ –¥–ª—è —Ä–æ–±–æ—Ç–∞)
                    'width': width_mm,    # –®–∏—Ä–∏–Ω–∞ –≤ –º–º
                    'height': height_mm,   # –í—ã—Å–æ—Ç–∞ –≤ –º–º
                    'angle': angle,        # –£–≥–æ–ª (–æ–±—â–∏–π)
                    'area_px': features_px["area"],
                    'area': area_mm2,
                    'aspect_ratio': features_px["aspect_ratio"],
                    'perimeter_px': features_px["perimeter"],
                    'perimeter': perimeter_mm,
                    'extent': features_px["extent"],
                    'hu_moments': features_px["hu_moments"], # –ü–∏–∫—Å–µ–ª—å–Ω—ã–µ
                    'circularity': features_px["circularity"],
                    'convexity_defects_count': features_px["convexity_defects_count"],
                    'avg_defect_depth_px': features_px["avg_defect_depth"],
                    'avg_defect_depth': avg_defect_depth_mm,
                    'avg_color': avg_color_bgr, # BGR —Ü–≤–µ—Ç
                    'predicted_category': predicted_category,
                    'contour': contour # –ö–æ–Ω—Ç—É—Ä –≤ –ø–∏–∫—Å–µ–ª—è—Ö (–Ω—É–∂–µ–Ω –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –∏, –≤–æ–∑–º–æ–∂–Ω–æ, —Ç—Ä–µ–∫–∏–Ω–≥–∞)
                }
                detections.append(detection)


            # --- 3. –¢—Ä–µ–∫–∏–Ω–≥ (–ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ ID) ---
            # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º track_id –∫ –¥–µ—Ç–µ–∫—Ü–∏—è–º —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ú–ú –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
            tracked_detections = self._assign_ids(detections)


            # --- 4. –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ CSV –∏ –û—Ç—Ä–∏—Å–æ–≤–∫–∞ ---
            objects_overlayed = corrected_frame.copy() # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è
            self._log_detections_to_record(tracked_detections) # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è CSV

            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ä–∞–±–æ—á—É—é –æ–±–ª–∞—Å—Ç—å –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (–ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º —Ü–≤–µ—Ç–æ–º?)
            # overlay = objects_overlayed.copy()
            # cv2.drawContours(overlay, [mask_to_use], -1, (255, 0, 0), -1) # –°–∏–Ω—è—è –∑–∞–ª–∏—Ç–∞—è –æ–±–ª–∞—Å—Ç—å
            # alpha = 0.2 # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å
            # objects_overlayed = cv2.addWeighted(overlay, alpha, objects_overlayed, 1 - alpha, 0)
            # TODO: –ú–∞—Å–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –æ–¥–Ω–∏–º –∫–æ–Ω—Ç—É—Ä–æ–º! –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å–ª–æ–∂–Ω–µ–µ. –ü–æ–∫–∞ –Ω–µ —Ä–∏—Å—É–µ–º –º–∞—Å–∫—É.

            for det in tracked_detections:
                 # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ü–ò–ö–°–ï–õ–¨–ù–´–ï –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
                 cx_px, cy_px = det['center_px']
                 # label = f"ID {det['track_id']} | {det['predicted_category']}" # –ö–æ—Ä–æ—Ç–∫–∏–π –ª–µ–π–±–ª
                 # –ü–æ–ª–Ω—ã–π –ª–µ–π–±–ª (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º)
                 label = f"ID {det.get('track_id','N/A')} | {det.get('predicted_category','unk')} | {det.get('width', 0):.1f}x{det.get('height', 0):.1f} mm"

                 # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∫–æ–Ω—Ç—É—Ä–∞
                 cv2.drawContours(objects_overlayed, [det['contour']], -1, (0, 255, 0), 2) # –ó–µ–ª–µ–Ω—ã–π –∫–æ–Ω—Ç—É—Ä
                 # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ü–µ–Ω—Ç—Ä–∞
                 cv2.circle(objects_overlayed, det['center_px'], 4, (0, 0, 255), -1) # –ö—Ä–∞—Å–Ω—ã–π —Ü–µ–Ω—Ç—Ä
                 # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
                 # –†–∞–∑–º–µ—â–∞–µ–º —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å —Ü–µ–Ω—Ç—Ä–æ–º
                 text_pos = (cx_px + 10, cy_px + 5)
                 cv2.putText(objects_overlayed, label, text_pos,
                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, # –£–º–µ–Ω—å—à–∏–º —à—Ä–∏—Ñ—Ç
                            (255, 255, 255), 2, cv2.LINE_AA) # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç —Å –æ–±–≤–æ–¥–∫–æ–π
                 cv2.putText(objects_overlayed, label, text_pos,
                            cv2.FONT_HERSHEY_SIMPLEX, 0.45,
                            (0, 0, 0), 1, cv2.LINE_AA) # –ß–µ—Ä–Ω—ã–π –≤–Ω—É—Ç—Ä–∏ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏


            # –î–æ–±–∞–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.putText(objects_overlayed, f"Frame: {frame_counter}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)


            # –≠–∫—Å–ø–æ—Ä—Ç CSV (–≤–æ–∑–º–æ–∂–Ω–æ, –¥–µ–ª–∞—Ç—å —Ä–µ–∂–µ?)
            if frame_counter % 60 == 0: # –ö–∞–∂–¥—ã–µ ~2 —Å–µ–∫—É–Ω–¥—ã
                 self.export_csv(os.path.join(var.APP_DIR, "detected_objects_log.csv"))

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return edges, objects_overlayed, tracked_detections

        except Exception as e:
             print(f"[ObjectDetector][ERROR] Unexpected error processing frame {frame_counter}: {e}")
             import traceback
             traceback.print_exc()
             # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á—Ç–æ-—Ç–æ, —á—Ç–æ–±—ã –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –Ω–µ –ø–∞–¥–∞–ª
             return None, corrected_frame.copy(), [] # –ì—Ä–∞–Ω–∏?, –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä, –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫


    def _assign_ids(self, current_detections):
        """
        –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç ID —Ç—Ä–µ–∫–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        –∏—Å–ø–æ–ª—å–∑—É—è –∞–ª–≥–æ—Ä–∏—Ç–º –í–µ–Ω–≥–µ—Ä—Å–∫–æ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–∏–≤—è–∑–∫–∏ (Hungarian algorithm).
        –†–∞–±–æ—Ç–∞–µ—Ç —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –≤ –ú–ò–õ–õ–ò–ú–ï–¢–†–ê–•.
        """
        # –¶–µ–Ω—Ç—Ä—ã –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤ (–≤ –º–º)
        track_centers_mm = np.array([track['last_center'] for track in self.tracks])
        # –¶–µ–Ω—Ç—Ä—ã —Ç–µ–∫—É—â–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π (–≤ –º–º)
        detection_centers_mm = np.array([det['center'] for det in current_detections])

        # --- –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π) ---
        cost_matrix = np.empty((len(self.tracks), len(current_detections)))
        if len(self.tracks) > 0 and len(current_detections) > 0:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º broadcasting –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –µ–≤–∫–ª–∏–¥–æ–≤—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
             cost_matrix = np.linalg.norm(track_centers_mm[:, np.newaxis, :] - detection_centers_mm[np.newaxis, :, :], axis=2)
        elif len(self.tracks) == 0:
             # –ï—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤, –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –Ω–æ–≤—ã–µ ID –≤—Å–µ–º –¥–µ—Ç–µ–∫—Ü–∏—è–º
             for i, det in enumerate(current_detections):
                 det['track_id'] = self.next_track_id
                 self.tracks.append({
                    'id': self.next_track_id,
                    'last_center': det['center'], # –º–º
                    'lost_frames': 0,
                    'object_name': det['predicted_category'] if det['predicted_category'] != "unknown" else None
                 })
                 self.next_track_id += 1
             return current_detections
        else: # –ï—Å—Ç—å —Ç—Ä–µ–∫–∏, –Ω–æ –Ω–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–π - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ
             pass

        assigned_detection_indices = set() # –ò–Ω–¥–µ–∫—Å—ã –¥–µ—Ç–µ–∫—Ü–∏–π, –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–∏—Å–≤–æ–µ–Ω ID —Ç—Ä–µ–∫–∞

        # --- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –í–µ–Ω–≥–µ—Ä—Å–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ ---
        if cost_matrix.size > 0:
             try:
                 # linear_sum_assignment –Ω–∞—Ö–æ–¥–∏—Ç –ø–∞—Ä—ã —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Å—É–º–º–∞—Ä–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é (—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º)
                 row_ind, col_ind = linear_sum_assignment(cost_matrix)

                 # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä (—Ç—Ä–µ–∫ <-> –¥–µ—Ç–µ–∫—Ü–∏—è) ---
                 for r, c in zip(row_ind, col_ind):
                     track_index = r
                     detection_index = c
                     distance = cost_matrix[track_index, detection_index]

                     # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Ä–æ–≥
                     if distance < self.MAX_DISTANCE_FOR_TRACKING:
                         # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–µ–º–ª–µ–º–æ - —Å–≤—è–∑—ã–≤–∞–µ–º —Ç—Ä–µ–∫ –∏ –¥–µ—Ç–µ–∫—Ü–∏—é
                         track = self.tracks[track_index]
                         detection = current_detections[detection_index]

                         # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫
                         track['last_center'] = detection['center'] # –ù–æ–≤—ã–π —Ü–µ–Ω—Ç—Ä –≤ –º–º
                         track['lost_frames'] = 0 # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
                         detection['track_id'] = track['id'] # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º ID —Ç—Ä–µ–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏

                         # –û–±–Ω–æ–≤–ª—è–µ–º –∏–º—è –æ–±—ä–µ–∫—Ç–∞ –≤ —Ç—Ä–µ–∫–µ, –µ—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞
                         if detection['predicted_category'] != "unknown":
                             track['object_name'] = detection['predicted_category']
                         elif track.get('object_name'):
                            # –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, –Ω–æ —Ç—Ä–µ–∫ –µ–µ –ø–æ–º–Ω–∏—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–∑ —Ç—Ä–µ–∫–∞
                            detection['predicted_category'] = track['object_name']


                         assigned_detection_indices.add(detection_index) # –ü–æ–º–µ—á–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é
                     # else: –≠—Ç–æ—Ç —Ç—Ä–µ–∫ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ (—Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ)

             except ValueError as e:
                  print(f"[ObjectDetector][ERROR] Error in linear_sum_assignment: {e}")
                  # –ú–æ–∂–µ—Ç –≤–æ–∑–Ω–∏–∫–Ω—É—Ç—å, –µ—Å–ª–∏ cost_matrix —Å–æ–¥–µ—Ä–∂–∏—Ç NaN –∏–ª–∏ inf

        # --- –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π ---
        for i, det in enumerate(current_detections):
            if i not in assigned_detection_indices:
                # –≠—Ç–∞ –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–µ –±—ã–ª–∞ —Å–≤—è–∑–∞–Ω–∞ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ç—Ä–µ–∫–æ–º
                det['track_id'] = self.next_track_id
                self.tracks.append({
                    'id': self.next_track_id,
                    'last_center': det['center'], # –º–º
                    'lost_frames': 0,
                    'object_name': det['predicted_category'] if det['predicted_category'] != "unknown" else None
                })
                self.next_track_id += 1

        # --- –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤ ---
        active_tracks = []
        for track in self.tracks:
             # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —Ç—Ä–µ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω –≤ —ç—Ç–æ–º –∫–∞–¥—Ä–µ
             found_in_current_frame = False
             for det in current_detections:
                 if det.get('track_id') == track['id']:
                     found_in_current_frame = True
                     break

             if not found_in_current_frame:
                 # –¢—Ä–µ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—É—â–µ–º –∫–∞–¥—Ä–µ - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ—Ç–µ—Ä—å
                 track['lost_frames'] += 1
             else:
                  track['lost_frames'] = 0 # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å–±—Ä–æ—Å–∏–º, –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω

             # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç—Ä–µ–∫, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø–æ—Ç–µ—Ä—è–Ω —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ
             if track['lost_frames'] <= self.MAX_TRACK_LOST_FRAMES:
                 active_tracks.append(track)
             # else:
                  # print(f"[Tracking] Track {track['id']} lost (>{self.MAX_TRACK_LOST_FRAMES} frames).")


        self.tracks = active_tracks # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–µ–∫–æ–≤


        # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ö–æ–¥: –µ—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, –Ω–æ —Ç—Ä–µ–∫ –µ–µ –ø–æ–º–Ω–∏—Ç
        for det in current_detections:
            if det.get('predicted_category') == "unknown":
                 track_id = det.get('track_id')
                 if track_id:
                     for track in self.tracks:
                         if track['id'] == track_id and track.get('object_name'):
                              det['predicted_category'] = track['object_name']
                              break # –ù–∞—à–ª–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–∫

        return current_detections # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏/–ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–º–∏ track_id


    def _log_detections_to_record(self, tracked_detections):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–µ—Ç–µ–∫—Ü–∏–π –≤ —Å–ø–∏—Å–æ–∫ self.records –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞."""
        for det in tracked_detections:
            # –°–æ–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
             self.records.append({
                'frame': det['frame'],
                'track_id': det.get('track_id', -1), # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID —Ç—Ä–µ–∫–µ—Ä–∞
                'category': det.get('predicted_category', 'unknown'),
                'center_x_mm': det.get('center', (0,0))[0],
                'center_y_mm': det.get('center', (0,0))[1],
                'width_mm': det.get('width', 0),
                'height_mm': det.get('height', 0),
                'angle_deg': det.get('angle', 0),
                'area_mm2': det.get('area', 0),
                'aspect_ratio': det.get('aspect_ratio', 0),
                'perimeter_mm': det.get('perimeter', 0),
                'extent': det.get('extent', 0),
                # 'hu_norm': np.linalg.norm(np.array(det['hu_moments'])), # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º? –∏–ª–∏ —Ö—Ä–∞–Ω–∏–º?
                'circularity': det.get('circularity', 0),
                'defects_count': det.get('convexity_defects_count', 0),
                'defect_depth_mm': det.get('avg_defect_depth', 0),
                'avg_color_b': det.get('avg_color', (0,0,0))[0],
                'avg_color_g': det.get('avg_color', (0,0,0))[1],
                'avg_color_r': det.get('avg_color', (0,0,0))[2],
             })


    def export_csv(self, path):
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª."""
        if not self.records:
            # print("[EXPORT] No records to export.")
            return
        try:
            df = pd.DataFrame(self.records)
            df.to_csv(path, index=False)
            print(f"[EXPORT] Saved {len(df)} records to {path}")
            # –û—á–∏—Å—Ç–∏—Ç—å –∑–∞–ø–∏—Å–∏ –ø–æ—Å–ª–µ —ç–∫—Å–ø–æ—Ä—Ç–∞?
            # self.records = []
        except Exception as e:
            print(f"[EXPORT][ERROR] Failed to export records to CSV {path}: {e}")


    def _get_center_pixels(self, rect):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ –∏–∑ MinAreaRect."""
        return (int(rect[0][0]), int(rect[0][1]))


    def _recognize_object(self, features_record):
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –æ–±—ä–µ–∫—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

        :param features_record: –°–ª–æ–≤–∞—Ä—å —Å –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –æ–±—ä–µ–∫—Ç–∞.
        :return: –ò–º—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (str) –∏–ª–∏ None.
        """
        if not self.IDENTIFICATION_CONFIG or not self.features_list:
             # print("[Recognize] No identification config loaded.")
             return None # –ù–µ –º–æ–∂–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –±–µ–∑ –∫–æ–Ω—Ñ–∏–≥–∞

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ –∫–æ–Ω—Ñ–∏–≥–µ
        for category_name, config_data in self.IDENTIFICATION_CONFIG.items():
             category_params = config_data.get("parameters", {})
             match = True # –§–ª–∞–≥ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ–∫—É—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

             # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –≤—Å–µ–º —Ñ–∏—á–∞–º, —É–∫–∞–∑–∞–Ω–Ω—ã–º –≤ features_list
             for feature_name in self.features_list:
                if feature_name not in features_record:
                    # print(f"[Recognize Debug] Feature '{feature_name}' not found in record for category '{category_name}'.")
                    match = False; break # –§–∏—á–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö - –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç

                if feature_name not in category_params:
                    # print(f"[Recognize Debug] Feature '{feature_name}' not defined in config for category '{category_name}'.")
                    match = False; break # –§–∏—á–∞ –Ω–µ –æ–ø–∏—Å–∞–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –¥–ª—è —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ - –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç

                # –ü–æ–ª—É—á–∞–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
                limits = category_params[feature_name]
                min_val = limits.get("min", -np.inf) # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
                max_val = limits.get("max", np.inf)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é + –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
                current_val = features_record[feature_name]

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω
                if not (min_val <= current_val <= max_val):
                     # print(f"[Recognize Debug] Feature '{feature_name}' mismatch for '{category_name}'. Value: {current_val:.2f}, Range: [{min_val:.2f}, {max_val:.2f}]")
                     match = False; break # –ó–Ω–∞—á–µ–Ω–∏–µ —Ñ–∏—á–∏ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ - –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç

             # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã (match –æ—Å—Ç–∞–ª—Å—è True)
             if match:
                # print(f"[Recognize] Object recognized as: {category_name}")
                return category_name # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–º—è –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –ø–æ–¥–æ—à–ª–∞
        # print("[Recognize] Object category is unknown.")
        return None


    def compute_shape_features(self, contour, rect):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–Ω—Ç—É—Ä–∞."""
        features = {}
        area = cv2.contourArea(contour)
        features["area"] = area

        perimeter = cv2.arcLength(contour, True)
        features["perimeter"] = perimeter

        # Bounding box (–Ω–µ –ø–æ–≤–µ—Ä–Ω—É—Ç—ã–π)
        x, y, w, h = cv2.boundingRect(contour)

        # Extent = Area / BoundingBoxArea
        bbox_area = w * h
        features["extent"] = area / bbox_area if bbox_area > 0 else 0

        # Hu Moments
        try:
            moments = cv2.moments(contour)
            hu_moments = cv2.HuMoments(moments).flatten()
            # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–±—Ä–æ—Å–∞
            features["hu_moments"] = [-np.sign(hu) * np.log10(abs(hu)) if hu != 0 else 0 for hu in hu_moments]
        except Exception: # –ú–æ–∂–µ—Ç –±—ã—Ç—å –¥–µ–ª–µ–Ω–∏–µ –Ω–∞ 0 –∏–ª–∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
            features["hu_moments"] = [0.0] * 7


        # Circularity = 4 * pi * Area / Perimeter^2
        features["circularity"] = (4 * math.pi * area / (perimeter ** 2)) if perimeter > 0 else 0

        # Convexity Defects
        defects_count = 0
        avg_defect_depth = 0.0
        try:
             if len(contour) > 3: # –ù—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 4 —Ç–æ—á–∫–∏ –¥–ª—è –¥–µ—Ñ–µ–∫—Ç–æ–≤
                hull_indices = cv2.convexHull(contour, returnPoints=False)
                if hull_indices is not None and len(hull_indices) > 2: # –í—ã–ø—É–∫–ª–∞—è –æ–±–æ–ª–æ—á–∫–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    # –í–∞–∂–Ω–æ: hull_indices –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω! –ù—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π?
                    # –°–º–æ—Ç—Ä–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é: "The output convex hull is represented as an array of indices of the contour points"
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å hull_indices –∫–∞–∫ –µ—Å—Ç—å
                    try:
                         defects = cv2.convexityDefects(contour, hull_indices)
                    except Exception as e_defects:
                        # –ò–Ω–æ–≥–¥–∞ –ø–∞–¥–∞–µ—Ç –∑–¥–µ—Å—å, –µ—Å–ª–∏ –∫–æ–Ω—Ç—É—Ä –∏ hull –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã
                        # print(f"[WARN] Convexity defects calculation failed: {e_defects}")
                        defects = None


                    if defects is not None:
                         # defects shape: (num_defects, 1, 4) -> [start_idx, end_idx, farthest_pt_idx, depth]
                         # –ì–ª—É–±–∏–Ω–∞ (depth) - —ç—Ç–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç –≤—ã–ø—É–∫–ª–æ–π –æ–±–æ–ª–æ—á–∫–∏ –¥–æ —Å–∞–º–æ–π –¥–∞–ª—å–Ω–µ–π —Ç–æ—á–∫–∏ –∫–æ–Ω—Ç—É—Ä–∞ / 256.0
                         valid_depths = [d[0][3] / 256.0 for d in defects if d[0][3] > 0] # –û—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω—É–ª–µ–≤—ã–µ
                         defects_count = len(valid_depths)
                         if defects_count > 0:
                             avg_defect_depth = np.mean(valid_depths)
        except Exception as e_hull:
              # –û—à–∏–±–∫–∏ –º–æ–≥—É—Ç –≤–æ–∑–Ω–∏–∫–∞—Ç—å —Å –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –∏–ª–∏ –≤—ã—Ä–æ–∂–¥–µ–Ω–Ω—ã–º–∏ –∫–æ–Ω—Ç—É—Ä–∞–º–∏
              # print(f"[WARN] Convex hull or defect calculation error: {e_hull}")
              pass # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (0)

        features["convexity_defects_count"] = defects_count
        features["avg_defect_depth"] = avg_defect_depth # –í –ø–∏–∫—Å–µ–ª—è—Ö

        # Aspect Ratio (–∏–∑ MinAreaRect)
        rect_width, rect_height = rect[1]
        features["aspect_ratio"] = max(rect_width, rect_height) / min(rect_width, rect_height) if min(rect_width, rect_height) > 0 else 0

        return features


    def compute_average_color(self, frame, contour, mask=None):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π BGR —Ü–≤–µ—Ç –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç—É—Ä–∞."""
        # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –∫–æ–Ω—Ç—É—Ä–∞
        contour_mask = np.zeros(frame.shape[:2], dtype=np.uint8)
        cv2.drawContours(contour_mask, [contour], -1, 255, -1) # –ó–∞–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç—É—Ä

        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±—â–∞—è –º–∞—Å–∫–∞ —Ä–∞–±–æ—á–µ–π –∑–æ–Ω—ã, –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Ö
        if mask is not None:
             final_mask = cv2.bitwise_and(contour_mask, mask)
        else:
             final_mask = contour_mask

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ü–≤–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ –ø–∏–∫—Å–µ–ª—è–º –≤–Ω—É—Ç—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–∞—Å–∫–∏
        if cv2.countNonZero(final_mask) > 0: # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –ø–∏–∫—Å–µ–ª–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
             mean_color_bgr_a = cv2.mean(frame, mask=final_mask)
             # –í–æ–∑–≤—Ä–∞—â–∞–µ–º BGR –∫–æ—Ä—Ç–µ–∂ (–±–µ–∑ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
             return (int(mean_color_bgr_a[0]), int(mean_color_bgr_a[1]), int(mean_color_bgr_a[2]))
        else:
             # –ï—Å–ª–∏ –º–∞—Å–∫–∞ –ø—É—Å—Ç–∞ (–∫–æ–Ω—Ç—É—Ä –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–Ω–µ —Ä–∞–±–æ—á–µ–π –∑–æ–Ω—ã?)
             return (0, 0, 0) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–µ—Ä–Ω—ã–π —Ü–≤–µ—Ç
```

**`calib.py` (–ù–µ–±–æ–ª—å—à–∏–µ –ø—Ä–∞–≤–∫–∏)**

```python
# calib.py (—Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –ø—Ä–∞–≤–∫–∞–º–∏)

import cv2
import numpy as np
import os
import time
import logging

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–ø–æ—Ä—Ç –∏–∑ variables —Å –ø—Å–µ–≤–¥–æ–Ω–∏–º–æ–º var
import variables as var

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def _get_charuco_board():
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç CharucoBoard."""
    try:
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ç–∏–ø —Å–ª–æ–≤–∞—Ä—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è OpenCV
        if not hasattr(cv2.aruco, var.DICT_TYPE):
            logging.error(f"ArUco dictionary type {var.DICT_TYPE} not found in cv2.aruco.")
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            fallback_dict = cv2.aruco.DICT_6X6_250
            logging.warning(f"Falling back to default dictionary: {fallback_dict}")
            aruco_dict = cv2.aruco.getPredefinedDictionary(fallback_dict)
        else:
             aruco_dict = cv2.aruco.getPredefinedDictionary(var.DICT_TYPE)

        board = cv2.aruco.CharucoBoard(
             (var.SQUARES_X, var.SQUARES_Y),
             var.SQUARE_LENGTH,
             var.MARKER_LENGTH,
             aruco_dict
         )
        return board, aruco_dict
    except Exception as e:
         logging.error(f"Failed to create Charuco board: {e}")
         raise # –ü–µ—Ä–µ–¥–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤—ã—à–µ, —Ç.–∫. –±–µ–∑ –¥–æ—Å–∫–∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞


def calibrate_camera_gui(source_type="video", camera_index=0, video_path=None, max_captures=50,
                         frame_callback=None, done_callback=None, stop_flag_getter=None):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫—É –∫–∞–º–µ—Ä—ã Charuco, –∏—Å–ø–æ–ª—å–∑—É—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫ –∏–ª–∏ –∫–∞–º–µ—Ä—É.
    –ü–µ—Ä–µ–¥–∞–µ—Ç –∫–∞–¥—Ä—ã –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫–∏ (–¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å GUI).

    :param source_type: "video" –∏–ª–∏ "camera".
    :param camera_index: –ò–Ω–¥–µ–∫—Å –∫–∞–º–µ—Ä—ã (–µ—Å–ª–∏ source_type="camera").
    :param video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É (–µ—Å–ª–∏ source_type="video").
    :param max_captures: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏.
    :param frame_callback: –§—É–Ω–∫—Ü–∏—è, –≤—ã–∑—ã–≤–∞–µ–º–∞—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞ (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç frame).
    :param done_callback: –§—É–Ω–∫—Ü–∏—è, –≤—ã–∑—ã–≤–∞–µ–º–∞—è –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç cameraMatrix, distCoeffs).
    :param stop_flag_getter: –§—É–Ω–∫—Ü–∏—è, –≤–æ–∑–≤—Ä–∞—â–∞—é—â–∞—è True –¥–ª—è –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏.
    """
    logging.info(f"Starting GUI calibration. Source: {source_type}, Index/Path: {camera_index if source_type=='camera' else video_path}, Max captures: {max_captures}")

    try:
        board, aruco_dict = _get_charuco_board()
    except Exception:
         if done_callback: done_callback(None, None)
         return # –ù–µ –º–æ–∂–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ –¥–æ—Å–∫–∏

    allCorners = []
    allIds = []
    imageSize = None # –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ –ø–µ—Ä–≤–æ–º—É –∫–∞–¥—Ä—É
    cap = None # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–¥–µ—Å—å

    # --- –û—Ç–∫—Ä—ã—Ç–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤–∏–¥–µ–æ ---
    try:
        if source_type == "video" and video_path and os.path.exists(video_path):
            cap = cv2.VideoCapture(video_path)
        elif source_type == "camera":
            cap = cv2.VideoCapture(camera_index)
            # –ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ –≤—Å–µ—Ö –∫–∞–º–µ—Ä–∞—Ö)
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, var.CAMERA_WIDTH)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, var.CAMERA_HEIGHT)
        else:
            error_msg = f"Invalid source type ('{source_type}') or video path ('{video_path}') does not exist."
            logging.error(error_msg)
            print(error_msg)
            if done_callback: done_callback(None, None)
            return

        if not cap or not cap.isOpened():
             error_msg = f"Could not open video source (Type: {source_type}, Index/Path: {camera_index if source_type=='camera' else video_path})."
             logging.error(error_msg)
             print(error_msg)
             if done_callback: done_callback(None, None)
             return
    except Exception as e:
        error_msg = f"Error opening video source: {e}"
        logging.error(error_msg)
        print(error_msg)
        if done_callback: done_callback(None, None)
        return


    # --- –¶–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤ ---
    frame_count = 0
    saved_frames = 0
    consecutive_failures = 0
    max_consecutive_failures = 150 # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, –µ—Å–ª–∏ –¥–æ–ª–≥–æ –Ω–µ—Ç —É—Å–ø–µ—Ö–æ–≤

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ ArUco
    try:
        parameters = cv2.aruco.DetectorParameters()
        # parameters.adaptiveThreshConstant = 7
        # parameters.adaptiveThreshWinSizeMin = 3
        # parameters.adaptiveThreshWinSizeMax = 23
        # parameters.adaptiveThreshWinSizeStep = 10
        parameters.minMarkerPerimeterRate = 0.01 # –í–∞–∂–Ω–æ –¥–ª—è –º–µ–ª–∫–∏—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
        # parameters.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX # –£–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ —É–≥–ª–æ–≤
    except AttributeError:
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π OpenCV
        parameters = cv2.aruco.DetectorParameters_create() # type: ignore

    print("[Calibration] Starting frame processing loop...")
    while True:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–ª–∞–≥–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        if stop_flag_getter and stop_flag_getter():
            logging.info("Stop flag triggered, exiting frame loop...")
            break

        try:
            ret, frame = cap.read()
        except Exception as e:
            logging.error(f"Error reading frame: {e}")
            ret = False

        if not ret:
            logging.info("End of video or failed to read frame.")
            break

        frame_count += 1
        if frame is None or frame.size == 0:
             logging.warning(f"Frame {frame_count} is empty, skipping.")
             continue

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        if imageSize is None:
             # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
             imageSize = gray.shape[::-1] # (width, height)
             logging.info(f"Image size detected: {imageSize}")

        # --- –î–µ—Ç–µ–∫—Ü–∏—è –º–∞—Ä–∫–µ—Ä–æ–≤ ArUco ---
        corners, ids, rejected = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        frame_display = frame.copy() # –ö–æ–ø–∏—è –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
        found_charuco = False

        if ids is not None and len(ids) > 0:
             # --- –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è —É–≥–ª–æ–≤ Charuco ---
             # minMarkers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º, –¥–∞–µ–º —à–∞–Ω—Å)
             try:
                ret_interp, charucoCorners, charucoIds = cv2.aruco.interpolateCornersCharuco(
                     markerCorners=corners, markerIds=ids, image=gray, board=board
                )
             except Exception as e:
                  logging.warning(f"Error during interpolateCornersCharuco: {e}")
                  ret_interp = 0 # –°—á–∏—Ç–∞–µ–º –Ω–µ—É–¥–∞—á–µ–π


             if ret_interp > var.MIN_CHARUCO_CORNERS:
                 # –£—Å–ø–µ—à–Ω–æ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≥–ª–æ–≤ Charuco
                 found_charuco = True
                 consecutive_failures = 0 # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞ –Ω–µ—É–¥–∞—á
                 # print(f"[DEBUG] Frame {frame_count}: Found {ret_interp} Charuco corners.")

                 # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (–∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä)
                 # –£—Å–ª–æ–≤–∏–µ frame_count % var.FRAME_INTERVAL == 0 –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ –¥–ª—è –≤–∏–¥–µ–æ
                 should_save = False
                 if source_type == "video" and frame_count % var.FRAME_INTERVAL == 0:
                     should_save = True
                 elif source_type == "camera": # –î–ª—è –∫–∞–º–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—â–µ, –Ω–æ –Ω–µ –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä
                     should_save = frame_count % 5 == 0 # –ö–∞–∂–¥—ã–π 5-–π –∫–∞–¥—Ä, –Ω–∞–ø—Ä–∏–º–µ—Ä

                 if should_save and saved_frames < max_captures:
                      # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–≥–ª–æ–≤
                     allCorners.append(charucoCorners)
                     allIds.append(charucoIds)
                     saved_frames += 1
                     logging.info(f"Frame {frame_count} captured ({saved_frames}/{max_captures}). Corners: {ret_interp}")

                 # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–≥–ª–æ–≤ Charuco
                 cv2.aruco.drawDetectedCornersCharuco(frame_display, charucoCorners, charucoIds, (0, 255, 0))
             # else: –ï—Å–ª–∏ —É–≥–ª–æ–≤ –º–∞–ª–æ, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º –∏ –Ω–µ —Ä–∏—Å—É–µ–º –∏—Ö


             # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ ArUco (–≤—Å–µ–≥–¥–∞, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
             cv2.aruco.drawDetectedMarkers(frame_display, corners, ids)

        if not found_charuco:
             consecutive_failures += 1
             # print(f"[DEBUG] Frame {frame_count}: No sufficient Charuco corners found (Failures: {consecutive_failures}). Markers found: {len(ids) if ids is not None else 0}")


        # --- –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–≤–µ—Ä–ª–µ—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π ---
        aspect_ratio = imageSize[0] / imageSize[1] if imageSize and imageSize[1] != 0 else 1.0
        text_color = (0, 255, 0) # –ó–µ–ª–µ–Ω—ã–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Å–Ω—ã–º, –µ—Å–ª–∏ –¥–∞–≤–Ω–æ –Ω–µ –±—ã–ª–æ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
        if consecutive_failures > 30: text_color = (0, 0, 255)

        cv2.putText(frame_display, f"Saved frames: {saved_frames}/{max_captures}",
                    (10, frame_display.shape[0] - 40), cv2.FONT_HERSHEY_SIMPLEX,
                    0.6, text_color, 2)
        cv2.putText(frame_display, f"Aspect Ratio: {aspect_ratio:.2f}",
                    (10, frame_display.shape[0] - 15), cv2.FONT_HERSHEY_SIMPLEX,
                    0.6, text_color, 2)

        # --- –ü–µ—Ä–µ–¥–∞—á–∞ –∫–∞–¥—Ä–∞ –≤ GUI ---
        if frame_callback:
             try:
                frame_callback(frame_display)
             except Exception as e:
                  # –õ–æ–≤–∏–º –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ GUI –æ–∫–Ω–æ —É–∂–µ –∑–∞–∫—Ä—ã—Ç–æ, –∞ –ø–æ—Ç–æ–∫ –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
                  logging.warning(f"Error in frame_callback (GUI might be closed): {e}")
                  # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –∫–æ–ª–±—ç–∫–∞, –≤–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç –ø—Ä–µ—Ä–≤–∞—Ç—å —Ü–∏–∫–ª?
                  # break

        # --- –£—Å–ª–æ–≤–∏—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞ ---
        if saved_frames >= max_captures:
            logging.info(f"Reached max captures ({max_captures}). Finishing.")
            break
        if consecutive_failures >= max_consecutive_failures:
             logging.warning(f"Exceeded max consecutive frame failures ({max_consecutive_failures}). Stopping.")
             break

        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å CPU –Ω–∞ 100% –∏ –¥–∞—Ç—å GUI –≤—Ä–µ–º—è
        time.sleep(0.01) # ~100 FPS max processing rate

    # --- –ö–æ–Ω–µ—Ü —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤ ---
    print("[Calibration] Frame processing loop finished.")
    if cap:
         cap.release()
         logging.info("Video capture released.")


    # --- –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ ---
    cameraMatrix = None
    distCoeffs = None

    if not allCorners or not allIds:
        logging.warning("No corners/IDs were collected for calibration.")
    elif imageSize is None:
         logging.error("Image size was not determined. Cannot calibrate.")
    elif len(allCorners) < 5: # –¢—Ä–µ–±—É–µ–º —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–∏—Ö –∫–∞–¥—Ä–æ–≤
         logging.warning(f"Too few ({len(allCorners)}) frames collected for reliable calibration.")
    else:
         print(f"[Calibration] Calibrating camera using {len(allCorners)} captured frames...")
         # –ù–∞—á–∞–ª—å–Ω—ã–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è (–º–æ–≥—É—Ç –±—ã—Ç—å —É–ª—É—á—à–µ–Ω—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–º–µ—Ä–µ)
         initial_cameraMatrix = np.array([[max(imageSize), 0.0, imageSize[0] / 2.0],
                                         [0.0, max(imageSize), imageSize[1] / 2.0],
                                         [0.0, 0.0, 1.0]], dtype=np.float64)
         initial_distCoeffs = np.zeros((5, 1), dtype=np.float64) # 5 for basic, 8 for rational? CALIB_RATIONAL_MODEL requires 8?

         calibration_flags = cv2.CALIB_RATIONAL_MODEL # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å 8 –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏

         try:
             # !–í–∞–∂–Ω–æ: allIds –∏ allCorners –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å list of numpy arrays
             # –£–±–µ–¥–∏–º—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
             if not isinstance(allIds[0], np.ndarray): allIds = [np.array(ids) for ids in allIds]
             if not isinstance(allCorners[0], np.ndarray): allCorners = [np.array(corners) for corners in allCorners]


             ret, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(
                  charucoCorners=allCorners,
                  charucoIds=allIds,
                  board=board,
                  imageSize=imageSize,
                  cameraMatrix=initial_cameraMatrix, # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
                  distCoeffs=initial_distCoeffs,    # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
                  flags=calibration_flags
             )

             print("\n===== Calibration Results =====")
             print(f"Reprojection Error: {ret:.4f}")
             print("Camera Matrix:")
             print(cameraMatrix)
             print("Distortion Coefficients:")
             print(distCoeffs.flatten()) # flatten –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞

             # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
             if ret > 0 and ret < 1.0 : # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–º, –µ—Å–ª–∏ –æ—à–∏–±–∫–∞ < 1.0 –ø–∏–∫—Å–µ–ª—è
                try:
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–æ–≤–æ–≥–æ
                    if os.path.exists(var.CALIBRATION_FILE):
                        os.remove(var.CALIBRATION_FILE)

                    np.savez(var.CALIBRATION_FILE,
                              cameraMatrix=cameraMatrix,
                              distCoeffs=distCoeffs,
                              rvecs=np.array(rvecs, dtype=object), # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ object array
                              tvecs=np.array(tvecs, dtype=object), # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ object array
                              reprojectionError=ret,
                              imageSize=np.array(imageSize)) # –°–æ—Ö—Ä–∞–Ω–∏–º –∏ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    logging.info(f"Calibration successful. Results saved to {var.CALIBRATION_FILE}")
                    print(f"Results saved to: {var.CALIBRATION_FILE}")
                except Exception as e:
                     logging.error(f"Error saving calibration data: {e}")
                     print(f"[ERROR] Error saving calibration data: {e}")
                     # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É—Å–ø–µ—à–Ω–∞, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ None
             else:
                 logging.warning(f"Calibration finished, but reprojection error ({ret:.4f}) is high or invalid. Results not saved.")
                 print(f"[WARN] Calibration reprojection error ({ret:.4f}) is too high. Results not saved.")
                 # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á—Ç–æ–±—ã done_callback –ø–æ–ª—É—á–∏–ª None
                 cameraMatrix = None
                 distCoeffs = None


         except cv2.error as e:
              logging.error(f"OpenCV error during calibration: {e}")
              print(f"[ERROR] OpenCV error during calibrateCameraCharuco: {e}")
         except Exception as e:
              logging.error(f"Unexpected error during calibration processing: {e}")
              print(f"[ERROR] Unexpected error during calibration processing: {e}")
              import traceback
              traceback.print_exc()

    # --- –í—ã–∑–æ–≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–±—ç–∫–∞ ---
    if done_callback:
        done_callback(cameraMatrix, distCoeffs)

    logging.info("Calibration process finished.")


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (–±–µ–∑ GUI)
    print("Running calibration from command line...")
    # –î–ª—è –∑–∞–ø—É—Å–∫–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤–∏–¥–µ–æ—Ñ–∞–π–ª –∏–ª–∏ –∫–∞–º–µ—Ä–∞
    # –°–æ–∑–¥–∞–¥–∏–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è stop_flag_getter
    stop_flag = False
    def stop_getter(): global stop_flag; return stop_flag

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    source = "video" # –∏–ª–∏ "camera"
    video = var.CALIBRATION_VIDEO_PATH
    cam_idx = var.CAMERA_INDEX
    max_frames = 50

    def print_frame(frame):
        # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª–∏ (–Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ, –Ω–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)
        # frame_small = cv2.resize(frame, (640, int(640*frame.shape[0]/frame.shape[1])))
        # cv2.imshow("Calibration Test", frame_small)
        # key = cv2.waitKey(1)
        # if key == ord('q'):
        #     global stop_flag
        #     stop_flag = True
        #     cv2.destroyAllWindows()
        print(".", end='', flush=True) # –ü—Ä–æ—Å—Ç–æ –ø–µ—á–∞—Ç–∞–µ–º —Ç–æ—á–∫—É –Ω–∞ –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä


    def print_result(matrix, coeffs):
         print("\nCalibration finished.")
         if matrix is not None:
             print("Success!")
         else:
             print("Failed or stopped.")

    # –ó–∞–ø—É—Å–∫ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
    calibrate_camera_gui(
        source_type=source,
        camera_index=cam_idx,
        video_path=video,
        max_captures=max_frames,
        frame_callback=print_frame,
        done_callback=print_result,
        stop_flag_getter=stop_getter
    )

    print("\nCommand line calibration test complete.")
```

**`robot_comm.py` (–ù–µ–±–æ–ª—å—à–∏–µ –ø—Ä–∞–≤–∫–∏)**

```python
# robot_comm.py
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ pyModbusTCP —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: pip install pyModbusTCP

from pyModbusTCP.client import ModbusClient
import logging
from datetime import datetime
import time # –¥–ª—è –ø–∞—É–∑—ã –ø—Ä–∏ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–µ

# –ù–∞—Å—Ç—Ä–æ–∏–º –ª–æ–≥–≥–µ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –¥–ª—è —ç—Ç–æ–≥–æ –º–æ–¥—É–ª—è
log = logging.getLogger(__name__)
log.setLevel(logging.INFO)
# –î–æ–±–∞–≤–∏–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫, –µ—Å–ª–∏ –æ–Ω –µ—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ
if not log.handlers:
     handler = logging.StreamHandler() # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
     formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
     handler.setFormatter(formatter)
     log.addHandler(handler)
     # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å FileHandler –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ main.py


class RobotComm:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±–º–µ–Ω–∞ –¥–∞–Ω–Ω—ã–º–∏ —Å —Ä–æ–±–æ—Ç–æ–º –ø–æ Modbus TCP."""
    def __init__(self, host="192.168.0.10", port=502, timeout=1.0, auto_reconnect=True, reconnect_delay=5):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Modbus TCP.

        :param host: IP –∞–¥—Ä–µ—Å —Ä–æ–±–æ—Ç–∞/—Å–µ—Ä–≤–µ—Ä–∞.
        :param port: –ü–æ—Ä—Ç Modbus TCP (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π 502).
        :param timeout: –¢–∞–π–º–∞—É—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è/–æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö.
        :param auto_reconnect: –ü—ã—Ç–∞—Ç—å—Å—è –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –ø—Ä–∏ —Ä–∞–∑—Ä—ã–≤–µ.
        :param reconnect_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–æ–π –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (—Å–µ–∫).
        """
        self.host = host
        self.port = port
        self.timeout = timeout
        self._client = ModbusClient(host=self.host, port=self.port,
                                   timeout=self.timeout, auto_open=False, auto_close=False)
        self._connected = False
        self.auto_reconnect = auto_reconnect
        self.reconnect_delay = reconnect_delay
        log.info(f"RobotComm initialized for {self.host}:{self.port}")

    def connect(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Modbus —Å–µ—Ä–≤–µ—Ä–æ–º."""
        if self._connected:
            log.warning("Already connected.")
            return True
        log.info(f"Attempting to connect to Modbus server at {self.host}:{self.port}...")
        try:
            self._connected = self._client.open()
            if self._connected:
                log.info("Connection successful.")
                print(f"[{datetime.now()}] ‚úÖ Connected to Modbus server at {self.host}:{self.port}")
            else:
                log.error("Connection failed.")
                print(f"[{datetime.now()}] ‚ùå Failed to connect to Modbus server.")
            return self._connected
        except Exception as e:
            self._connected = False
            log.exception(f"Exception during connection attempt: {e}") # –ò—Å–ø–æ–ª—å–∑—É–µ–º log.exception –¥–ª—è —Å—Ç–µ–∫–∞
            print(f"[{datetime.now()}] ‚ùå Exception during connection: {e}")
            return False

    def disconnect(self):
        """–†–∞–∑—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Modbus —Å–µ—Ä–≤–µ—Ä–æ–º."""
        if not self._connected:
            log.info("Already disconnected.")
            return
        log.info("Disconnecting from Modbus server...")
        try:
             if self._client.is_open: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º
                 self._client.close()
             self._connected = False
             log.info("Disconnected successfully.")
             print(f"[{datetime.now()}] üîå Disconnected from Modbus server.")
        except Exception as e:
            log.exception(f"Exception during disconnection: {e}")
            print(f"[{datetime.now()}] ‚ö†Ô∏è Exception during disconnection: {e}")
            self._connected = False # –°—á–∏—Ç–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–º –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ


    def is_connected(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
        # client.is_open –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –≤—Å–µ–≥–¥–∞ –Ω–∞–¥–µ–∂–Ω—ã–º –±–µ–∑ –æ–ø–µ—Ä–∞—Ü–∏–∏ —á—Ç–µ–Ω–∏—è/–∑–∞–ø–∏—Å–∏
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º —Ñ–ª–∞–≥ self._connected
        # return self._connected and self._client.is_open
        return self._connected

    def send_data(self, obj_id, x_mm, y_mm, width_mm, height_mm, angle, category_code, start_register=0):
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ–± –æ–±—ä–µ–∫—Ç–µ –≤ —Ä–µ–≥–∏—Å—Ç—Ä—ã Modbus.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –ø–æ–ø—ã—Ç–∫—É –∑–∞–ø–∏—Å–∏. –í–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏ –∞–≤—Ç–æ-—Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç, –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ.

        :param obj_id: ID –æ–±—ä–µ–∫—Ç–∞ (int).
        :param x_mm, y_mm: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–∞ –≤ –º–º (float).
        :param width_mm, height_mm: –†–∞–∑–º–µ—Ä—ã –≤ –º–º (float).
        :param angle: –£–≥–æ–ª –≤ –≥—Ä–∞–¥—É—Å–∞—Ö (float).
        :param category_code: –ö–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (int).
        :param start_register: –ê–¥—Ä–µ—Å –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ (int).
        :return: True –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ.
        """
        if not self.is_connected():
            log.warning("Attempted to send data while disconnected.")
            if self.auto_reconnect:
                 log.info("Auto-reconnect enabled. Trying to reconnect...")
                 print(f"[{datetime.now()}] üîå Modbus connection lost. Attempting to reconnect...")
                 time.sleep(self.reconnect_delay)
                 if not self.connect():
                     log.error("Reconnect attempt failed. Cannot send data.")
                     print(f"[{datetime.now()}] ‚ùå Reconnect failed. Data not sent.")
                     return False
                 # –ï—Å–ª–∏ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç —É—Å–ø–µ—à–µ–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É
                 log.info("Reconnect successful. Proceeding with data send.")
            else:
                 print(f"[{datetime.now()}] üîå Not connected. Cannot send data.")
                 return False

        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
        # –£–º–Ω–æ–∂–∞–µ–º float –Ω–∞ 100 –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ int –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ (2 –∑–Ω–∞–∫–∞ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π)
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤–ª–µ–∑–∞—é—Ç –≤ 16-–±–∏—Ç–Ω—ã–π —Ä–µ–≥–∏—Å—Ç—Ä (-32768 to 32767 –∏–ª–∏ 0 to 65535)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º signed int –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (–º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏?)
        # –ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ —Ä–æ–±–æ—Ç –æ–∂–∏–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "—Å–æ—Ç—ã–µ –¥–æ–ª–∏ –º–º", –∫–∞–∫ signed int.
        try:
             # –ü—Ä–∏–≤–æ–¥–∏–º –∫ int, —É–º–Ω–æ–∂–∏–≤ –Ω–∞ 100
            # –ü—Ä–∏–º: –¥–ª—è –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –∫–∞–∫ 32-bit (–¥–≤–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
            data_to_send = [
                int(obj_id) & 0xFFFF, # ID –∫–∞–∫ 16-–±–∏—Ç –±–µ–∑ –∑–Ω–∞–∫–∞
                int(x_mm * 100),
                int(y_mm * 100),
                int(width_mm * 100) & 0xFFFF, # –†–∞–∑–º–µ—Ä—ã –∫–∞–∫ 16-–±–∏—Ç –±–µ–∑ –∑–Ω–∞–∫–∞
                int(height_mm * 100) & 0xFFFF,
                int(angle * 100),      # –£–≥–æ–ª —Å–æ –∑–Ω–∞–∫–æ–º ( -XX.XX –¥–æ +XX.XX )
                int(category_code) & 0xFFFF # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∫–∞–∫ 16-–±–∏—Ç –±–µ–∑ –∑–Ω–∞–∫–∞
            ]
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ (–±–∞–∑–æ–≤–∞—è)
            for val in data_to_send[1:]: # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ –∑–Ω–∞–∫–æ–º –∏ –±–µ–∑
                 if not (-32768 <= val <= 65535): # –ì—Ä—É–±–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ 16 –±–∏—Ç
                      log.warning(f"Value {val} might be out of 16-bit range. Clamping may occur.")
                      # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (clamping) –∑–¥–µ—Å—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏


        except ValueError as e:
            log.error(f"Invalid data format for Modbus sending: {e}. Data: {[obj_id, x_mm, y_mm, width_mm, height_mm, angle, category_code]}")
            print(f"[{datetime.now()}] ‚ùå Invalid data format: {e}. Data not sent.")
            return False

        # --- –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
        log.debug(f"Sending data to registers starting at {start_register}: {data_to_send}")
        try:
            # write_multiple_registers –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ int
            success = self._client.write_multiple_registers(start_register, data_to_send)

            if success:
                # log.info(f"Data sent successfully: {data_to_send}") # –£–º–µ–Ω—å—à–∏–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ —É—Å–ø–µ—Ö–µ
                # print(f"[{datetime.now()}] -> Data sent: ID:{obj_id}, Cat:{category_code}, Pos:({x_mm:.1f},{y_mm:.1f})")
                return True
            else:
                log.error(f"Failed to send data using write_multiple_registers. Start reg: {start_register}, Data: {data_to_send}")
                print(f"[{datetime.now()}] ‚ùå Failed to send data via Modbus (write failed).")
                # –ü—Ä–∏ –Ω–µ—É–¥–∞—á–Ω–æ–π –∑–∞–ø–∏—Å–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ
                self._connected = self._client.is_open # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                return False
        except Exception as e:
            # –û—à–∏–±–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã —Å —Ç–∞–π–º–∞—É—Ç–æ–º, —Ä–∞–∑—Ä—ã–≤–æ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏ —Ç.–¥.
            log.exception(f"Exception during data sending: {e}")
            print(f"[{datetime.now()}] ‚ùå Exception during data sending: {e}")
            self._connected = False # –°—á–∏—Ç–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–º –ø—Ä–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–∏
            return False

```

**`variables.py` (–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∫–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç)**

```python
# variables.py

import os
import cv2 # –ù—É–∂–µ–Ω –¥–ª—è cv2.aruco –∫–æ–Ω—Å—Ç–∞–Ω—Ç

# ---- –ë–∞–∑–æ–≤—ã–µ –ø—É—Ç–∏ ----
# –ö–æ—Ä–µ–Ω—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
APP_DIR = os.path.join(BASE_DIR, "app_data")

# ---- –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ main.py –Ω–∞ —Å—Ç–∞—Ä—Ç–µ) ---
# if not os.path.exists(APP_DIR):
#     try:
#         os.makedirs(APP_DIR)
#         print(f"Created application data directory: {APP_DIR}")
#     except OSError as e:
#         print(f"[ERROR] Could not create app_data directory: {e}")
#         # –ß—Ç–æ –¥–µ–ª–∞—Ç—å –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ? –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã–π—Ç–∏ –∏–ª–∏ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.

# ---- –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –¥–∞–Ω–Ω—ã—Ö ----
CALIBRATION_FILE = os.path.join(APP_DIR,"camera_calibration.npz")
LOG_FILE = os.path.join(APP_DIR, "application_log.txt") # –ò–∑–º–µ–Ω–∏–ª –∏–º—è –ª–æ–≥-—Ñ–∞–π–ª–∞
DATA_COLLECTION_CSV = os.path.join(APP_DIR, "collected_data.csv")
IDENTIFICATION_CONFIG = os.path.join(APP_DIR, "identification_params.json")
PARAMETERS_CONFIG = os.path.join(APP_DIR, "detection_params.json")
DETECTED_OBJECTS_CSV = os.path.join(APP_DIR, "detected_objects_log.csv") # –î–ª—è –ª–æ–≥–∞ ObjectDetector

# ---- –ü—É—Ç–∏ –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–∞–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ----
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ (r"...") –∏–ª–∏ –¥–≤–æ–π–Ω—ã–µ —Å–ª–µ—à–∏ (\\) –¥–ª—è –ø—É—Ç–µ–π Windows
CALIBRATION_VIDEO_PATH = r'C:\path\to\your\calibration_video.mp4' # <-- –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –ü–£–¢–¨
WORKING_VIDEO_PATH = r"C:\path\to\your\working_video.mp4"        # <-- –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –í–ê–® –ü–£–¢–¨

# ---- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ö–∞–º–µ—Ä—ã ----
CAMERA_INDEX = 0       # –ò–Ω–¥–µ–∫—Å –≤–µ–±-–∫–∞–º–µ—Ä—ã (0 - –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è, 1+ - –≤–Ω–µ—à–Ω–∏–µ)
CAMERA_WIDTH = 1280    # –ñ–µ–ª–∞–µ–º–∞—è —à–∏—Ä–∏–Ω–∞ –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã (–º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è)
CAMERA_HEIGHT = 720    # –ñ–µ–ª–∞–µ–º–∞—è –≤—ã—Å–æ—Ç–∞ –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã
CAMERA_FPS = 30        # –ñ–µ–ª–∞–µ–º–∞—è —á–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤
# CAMERA_ROTATION = 0    # –ü–æ–≤–æ—Ä–æ—Ç –∫–∞–¥—Ä–∞ (0, 90, 180, 270) - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∫–∞ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞
# CAMERA_FLIP = False    # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∫–∞ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞

# ---- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ö–∞–ª–∏–±—Ä–æ–≤–∫–∏ –ö–∞–º–µ—Ä—ã (ChArUco) ----
MAX_CAPTURES = 50               # –ú–∞–∫—Å. –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (–±—ã–ª–æ 100)
FRAME_INTERVAL = 15             # –ò–Ω—Ç–µ—Ä–≤–∞–ª –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ (–±—ã–ª–æ 60)
DICT_TYPE = cv2.aruco.DICT_5X5_1000 # –¢–∏–ø —Å–ª–æ–≤–∞—Ä—è ArUco –º–∞—Ä–∫–µ—Ä–æ–≤
SQUARES_X = 5                   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ –Ω–∞ –¥–æ—Å–∫–µ
SQUARES_Y = 7                   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ –Ω–∞ –¥–æ—Å–∫–µ
SQUARE_LENGTH = 0.0304          # (–ú–ï–¢–†–´!) –î–ª–∏–Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ã –∫–≤–∞–¥—Ä–∞—Ç–∞ –Ω–∞ –¥–æ—Å–∫–µ (30.4 –º–º)
MARKER_LENGTH = 0.0154          # (–ú–ï–¢–†–´!) –î–ª–∏–Ω–∞ —Å—Ç–æ—Ä–æ–Ω—ã –º–∞—Ä–∫–µ—Ä–∞ –≤–Ω—É—Ç—Ä–∏ –∫–≤–∞–¥—Ä–∞—Ç–∞ (15.4 –º–º)
MIN_CHARUCO_CORNERS = 10        # –ú–∏–Ω. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —É–≥–ª–æ–≤ Charuco –¥–ª—è —É—á–µ—Ç–∞ –∫–∞–¥—Ä–∞ (–±—ã–ª–æ 12)

# ---- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –î–µ—Ç–µ–∫—Ü–∏–∏ –û–±—ä–µ–∫—Ç–æ–≤ (–ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ----
# –û–Ω–∏ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ã –∏–∑ PARAMETERS_CONFIG, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
SCALE = 0.75             # –ú–∞—Å—à—Ç–∞–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
BLUR_KERNEL = 5          # –†–∞–∑–º–µ—Ä —è–¥—Ä–∞ —Ä–∞–∑–º—ã—Ç–∏—è –ì–∞—É—Å—Å–∞ (–Ω–µ—á–µ—Ç–Ω–æ–µ!)
CANNY_LOW = 50           # –ù–∏–∂–Ω–∏–π –ø–æ—Ä–æ–≥ Canny
CANNY_HIGH = 150         # –í–µ—Ä—Ö–Ω–∏–π –ø–æ—Ä–æ–≥ Canny
MIN_AREA = 100           # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
MAX_AREA = 50000         # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –∫–æ–Ω—Ç—É—Ä–∞ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
CONVERSION_FACTOR = 1.0  # –ö–û–≠–§–§–ò–¶–ò–ï–ù–¢ –º–º/–ø–∏–∫—Å–µ–ª—å (–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π –∏–ª–∏ –≤—Ä—É—á–Ω—É—é)

# --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –†–∞–±–æ—á–µ–π –û–±–ª–∞—Å—Ç–∏ ---
REFERENCE_OBJECT_WIDTH_MM = 210.0 # –®–∏—Ä–∏–Ω–∞ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ –º–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ—Ä–æ—Ç–∫–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ A4)
WORKING_AREA_MIN_SIZE_RATIO = 0.1 # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å—Ç–æ—Ä–æ–Ω—ã —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–∞–¥—Ä–∞ (10%)
WORKING_AREA_MAX_SIZE_RATIO = 0.9 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å—Ç–æ—Ä–æ–Ω—ã —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–∞–¥—Ä–∞ (90%)
# ASPECT_RATIO_TOLERANCE = 0.05   # –î–æ–ø—É—Å–∫ –¥–ª—è —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –æ–±–ª–∞—Å—Ç–∏ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

# ---- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¢—Ä–µ–∫–∏–Ω–≥–∞ –û–±—ä–µ–∫—Ç–æ–≤ ----
MAX_LOST_FRAMES = 10       # –ú–∞–∫—Å. –∫–∞–¥—Ä–æ–≤ –ø–æ—Ç–µ—Ä–∏ —Ç—Ä–µ–∫–∞ (–±—ã–ª–æ 5)
MAX_DISTANCE = 75          # –ú–∞–∫—Å. —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–≤ –ú–ú!) –¥–ª—è —Å–≤—è–∑–∏ —Ç—Ä–µ–∫–∞ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π (–±—ã–ª–æ 50 –ø–∏–∫—Å–µ–ª–µ–π!)

# ---- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Modbus TCP ----
MODBUS_TCP_HOST = "192.168.0.10" # IP –∞–¥—Ä–µ—Å —Ä–æ–±–æ—Ç–∞/—Å–µ—Ä–≤–µ—Ä–∞
MODBUS_TCP_PORT = 502            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä—Ç Modbus TCP
MODBUS_TIMEOUT = 1.0             # –¢–∞–π–º–∞—É—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è/–æ–ø–µ—Ä–∞—Ü–∏–∏ (—Å–µ–∫—É–Ω–¥—ã)
MODBUS_AUTO_RECONNECT = True     # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
MODBUS_RECONNECT_DELAY = 5       # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Ä–µ–∫–æ–Ω–Ω–µ–∫—Ç–æ–º (—Å–µ–∫—É–Ω–¥—ã)

# ---- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ (–ø—Ä–∏–º–µ—Ä) ----
# –ú–∞–ø–ø–∏–Ω–≥ –∏–º–µ–Ω –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ –∫–æ–¥—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–æ–±–æ—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ main.py)
# OBJECT_CATEGORY_CODES = {
#     "unknown": 0,
#     "circular_white": 1,
#     "circular_pink": 2, # –∏–ª–∏ 'circular_red'
#     "circular_black": 3,
#     "rhombus_white": 4, # –∏–ª–∏ 'rectangle_white'
#     "rhombus_pink": 5,
#     "rhombus_black": 6,
#     # ... –¥—Ä—É–≥–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ...
# }
```

–ù–µ –∑–∞–±—É–¥—å—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª—ã —Å –Ω–æ–≤—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ (`main_refactored.py`, `debug_window.py`, `utils.py`) –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ. –¢–∞–∫–∂–µ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç–∏ –≤ `variables.py` (–æ—Å–æ–±–µ–Ω–Ω–æ `CALIBRATION_VIDEO_PATH` –∏ `WORKING_VIDEO_PATH`) —É–∫–∞–∑–∞–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è –≤–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã.

–≠—Ç–æ—Ç —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –¥–æ–ª–∂–µ–Ω —Å–¥–µ–ª–∞—Ç—å –∫–æ–¥ –±–æ–ª–µ–µ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º. –£–¥–∞—á–∏ —Å –ø—Ä–æ–µ–∫—Ç–æ–º!